{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning eines GPT-3-Modell\n",
    "\n",
    "In diesem Notebook wird dein Datensatz zusammengestellt, der ausschließlich zum Finetuning eines GPT-3-Modells dient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import re\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datensatz erstellen für GPT3 Finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rest = pd.read_csv('01_Data\\dataset_Google-Maps-Reviews-Restaurants_2023-03-26_09-43-08-320.csv')\n",
    "df_act = pd.read_csv('01_Data\\dataset_Google-Maps-Reviews-Activities_2023-03-26_11-08-15-435.csv')\n",
    "df_hotel = pd.read_csv('01_Data\\dataset_Google-Maps-Reviews-Hotels_2023-03-26_11-34-16-492.csv')\n",
    "\n",
    "print('Restaurants (Shape): ', df_rest.shape)\n",
    "print('Activities (Shape): ', df_act.shape)\n",
    "print('Hotels (Shape): ', df_hotel.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idee: nur den Text berücksichtigen. Noch kein Fokus auf zwei Modalitäten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "df_fine_tuning = pd.concat([df_rest, df_act, df_hotel], axis=0)\n",
    "\n",
    "df_fine_tuning = df_fine_tuning.reset_index(drop=True)\n",
    "df_fine_tuning = df_fine_tuning.drop_duplicates(subset=['reviewId'])\n",
    "print('All (raw): ', df_fine_tuning.shape)\n",
    "\n",
    "df_fine_tuning = df_fine_tuning.dropna(subset=['text'])\n",
    "df_fine_tuning = df_fine_tuning[['text', 'reviewId', 'url', 'placeId','categoryName', 'stars', 'reviewImageUrls/0']]\n",
    "print('All with text: ', df_fine_tuning.shape)\n",
    "df_fine_tuning['text'] = df_fine_tuning['text'].astype(str)\n",
    "\n",
    "df_fine_tuning = df_fine_tuning[~df_fine_tuning['reviewId'].isin(df_reduced['reviewId'])]\n",
    "print('All (ohne späteren Base-Datensatz reviews): ', df_fine_tuning.shape)\n",
    "df_fine_tuning.to_csv('finetuning_gpt3_v2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt. Andere Sprachen rausfiltern und Einträge die im Base-Datensatz sind rausfiltern. @TODO: RAUSFINDEN, OB AUF ANDERE LOCATOINS TRAINIEREN ODER DIE SELBEN WIE IM BASE_..._.csv Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_tuning = pd.read_csv (\"finetuning_gpt3_v2.csv\")\n",
    "df_fine_tuning.iloc[1179:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows which do not have an english 'text' column and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_gpt3(row):\n",
    "    category = row[\"categoryName\"]\n",
    "    return f\"Google Maps review about a {category}. ->\"\n",
    "\n",
    "def generate_prompt_gpt35turbo(row):\n",
    "    category = row[\"categoryName\"]\n",
    "    return f\"Write a Google Maps review about a {category}.\"\n",
    "\n",
    "# hier die Promt für ein 1:1-Real-Pendant-Mapping mit GPT3.5 Turbo (OUTDATED)\n",
    "def generate_prompt_gpt35turbo(row):\n",
    "    stars = row[\"stars\"]\n",
    "    category = row[\"categoryName\"]\n",
    "    keywords = row[\"keywords_only\"]\n",
    "    keywords = keywords[1:-1].split(\",\")[:3]\n",
    "    keywords = [k.strip() for k in keywords]\n",
    "    keywords = \", \".join(keywords)\n",
    "    keywords = keywords.replace(\"'\", \"\")\n",
    "    return f\"Write a {stars} stars Google Maps review about a {category}, with the following keywords: {keywords}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_tuning = pd.read_csv(\"finetuning_gpt3_v2.csv\")\n",
    "df_reduced = pd.read_csv(\"base_keywords_sentiment_reduced.csv\")\n",
    "\n",
    "print(df_fine_tuning.shape)\n",
    "\n",
    "df_fine_tuning[\"prompt\"] = df_fine_tuning.apply(generate_prompt_gpt3, axis=1)\n",
    "df_fine_tuning[\"completion\"] = df_fine_tuning[\"text\"] + \"###\"\n",
    "\n",
    "print(df_fine_tuning.shape)\n",
    "print(df_fine_tuning.head)\n",
    "\n",
    "df_fine_tuning = pd.read_csv (\"finetuning_gpt3_v2.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1: Online-Tool für Finetuning GPT-3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: Training im CODE (How to fine-tune a GPT-3 model for specific prompts)\n",
    "\n",
    "https://www.indiehackers.com/post/how-to-fine-tune-a-gpt-3-model-using-python-with-your-own-data-for-improved-performance-198dfe51d6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm constantly looking for ways to automate the work with support requests. An idea has been to fine-tune a GPT-3 model to answer common support-related questions.\n",
    "\n",
    "**Here's how you can fine-tune a GPT-3 model with Python with your own data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this walkthrough, we'll fine-tune a GPT-3 model to answer common support-related questions.\n",
    "\n",
    "Detailed step-by-step intructions for this repo in this blog post: https://norahsakal.com/blog/fine-tune-gpt3-model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define OpenAI API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('apikey_openai.txt', 'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to end each `prompt` with a suffix. According to the [OpenAI API reference](https://beta.openai.com/docs/guides/fine-tuning \"fine-tuning reference\"), you can use ` ->`.\n",
    "\n",
    "Also, make sure to end each `completion` with a suffix as well; I'm using `.\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = [{\n",
    "    \"prompt\": \"Prompt ->\",\n",
    "    \"completion\": \" Ideal answer.\\n\"\n",
    "},{\n",
    "    \"prompt\":\"Prompt ->\",\n",
    "    \"completion\": \" Ideal answer.\\n\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': 'Prompt ->', 'completion': ' Ideal answer.\\n'}, {'prompt': 'Prompt ->', 'completion': ' Ideal answer.\\n'}]\n"
     ]
    }
   ],
   "source": [
    "print(data_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dict as JSONL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data need to be a JSONL document.\n",
    "JSONL file is a newline-delimited JSON file.\n",
    "More info about JSONL: https://jsonlines.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_name = \"training_data.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as outfile:\n",
    "    for entry in data_file:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "print(\"Done\")\n",
    "print(file_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check JSONL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 2 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- There are 1 duplicated prompt-completion sets. These are rows: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ERROR in common_suffix validator: All prompts are identical: `Prompt ->`\n",
      "Consider leaving the prompts blank if you want to do open-ended generation, otherwise ensure prompts are different\n",
      "\n",
      "Aborting...\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f training_data.jsonl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload file to your OpenAI account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_response = openai.File.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "upload_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = upload_response.id\n",
    "file_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default model is **Curie**. \n",
    "\n",
    "If you'd like to use **DaVinci** instead, then add it as a base model to fine-tune:\n",
    "\n",
    "```openai.FineTune.create(training_file=file_id, model=\"davinci\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_response = openai.FineTune.create(training_file=file_id)\n",
    "fine_tune_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check fine-tune progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the progress with `openai.FineTune.list_events(id=fine_tune_response.id)` and get a list of all the fine-tuning events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_events = openai.FineTune.list_events(id=fine_tune_response.id)\n",
    "fine_tune_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the progress with `openai.FineTune.retrieve(id=fine_tune_response.id)` and get an object with the fine-tuning job data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_response = openai.FineTune.retrieve(id=fine_tune_response.id)\n",
    "retrieve_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting fine_tuned_model as null\n",
    "During the fine-tuning process, the **fine_tuned_model** key may not be immediately available in the fine_tune_response object returned by `openai.FineTune.create()`.\n",
    "\n",
    "To check the status of your fine-tuning process, you can call the `openai.FineTune.retrieve()` function and pass in the **fine_tune_response.id**. This function will return a JSON object with information about the training status, such as the current epoch, the current batch, the training loss, and the validation loss.\n",
    "\n",
    "After the fine-tuning process is complete, you can check the status of all your fine-tuned models by calling `openai.FineTune.list()`. This will list all of your fine-tunes and their current status.\n",
    "\n",
    "Once the fine-tuning process is complete, you can retrieve the fine_tuned_model key by calling the `openai.FineTune.retrieve()` function again and passing in the fine_tune_response.id. This will return a JSON object with the key fine_tuned_model and the ID of the fine-tuned model that you can use for further completions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `fine_tune_response.fine_tuned_model != None` then the key **fine_tuned_model** is availble from the fine_tune_response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune_response.fine_tuned_model != None:\n",
    "    fine_tuned_model = fine_tune_response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `fine_tune_response.fine_tuned_model == None:` you can get the **fine_tuned_model** by listing all fine-tune events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune_response.fine_tuned_model == None:\n",
    "    fine_tune_list = openai.FineTune.list()\n",
    "    fine_tuned_model = fine_tune_list['data'][0].fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `fine_tune_response.fine_tuned_model == None:` you can get the **fine_tuned_model** key by retrieving the fine-tune job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune_response.fine_tuned_model == None:\n",
    "    fine_tuned_model = openai.FineTune.retrieve(id=fine_tune_response.id).fine_tuned_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the new model on a new prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to end the prompt with the same suffix as we used in the training data; ` ->`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"NEW PROMPT ->\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=10, # Change amount of tokens for longer completion\n",
    "  temperature=0\n",
    ")\n",
    "answer['choices'][0]['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
