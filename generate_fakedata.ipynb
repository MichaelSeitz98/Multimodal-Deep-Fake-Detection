{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from keybert import KeyBERT\n",
    "import langdetect\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os \n",
    "import glob\n",
    "\n",
    "from tabgan.sampler import Sampler\n",
    "\n",
    "\n",
    "from faker import Faker\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "# model = KeyBERT('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "with open(\"apikey_helga.txt\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "print(api_key)\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text: Finetuned GPT3 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_list = openai.FineTune.list()\n",
    "fine_tuned_model = fine_tune_list['data'][0].fine_tuned_model\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"A Google Maps review about a steak house. ###\"\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=200, # Change amount of tokens for longer completion\n",
    "  temperature=1,\n",
    "  stop = \"END\"\n",
    ")\n",
    "print(answer['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_finetuned(row):\n",
    "    catgeoryName = row['categoryName'].lower()\n",
    "    prompt = \"A Google Maps review about a \" + catgeoryName + \". ###\"\n",
    "    print(prompt)\n",
    "    answer = openai.Completion.create(\n",
    "      model=fine_tuned_model,\n",
    "      prompt=prompt,\n",
    "      max_tokens=200, # Change amount of tokens for longer completion\n",
    "      temperature=1, \n",
    "      stop = \"END\"\n",
    "    )\n",
    "    return answer['choices'][0]['text']\n",
    "\n",
    "# def gpt3_5_turbo(row):\n",
    "#     prompt = \"Write a Google Maps review about a \" + row['categoryName'] + \". In Style of a Google user that writes a review about a place.\"\n",
    "#     role = \"In stlye of a google user that writes a review about a place.\"\n",
    "#     prompt = \"Write a Google Maps review about a \" + row['categoryName']+\".\"\n",
    "#     print(prompt)\n",
    "#     return chatGPT(api_key, role).question(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outdated: Nur für Test:  gpt3_5_turbo vs gpt3_finetuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## df_test.to_csv('test_df_showcase20gpt.csv')\n",
    "# # print(\"Done with gpt3_finetuned_v1 text generation.\")\n",
    "\n",
    "# df_test = pd.read_csv('test_df_showcase.csv')\n",
    "# df_test['gpt3_finetuned_v1'] = df_test.apply(gpt3_finetuned, axis=1)\n",
    "# df_test.to_csv('test_df_showcase.csv')\n",
    "# print(\"Done with gpt3.5_turbo text generation.\")\n",
    "\n",
    "# print(df_test)\n",
    "# print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('test_df_showcase.csv')\n",
    "# df_test['gpt3.5_turbo'] = df_test['gpt3.5_turbo'].astype(str)\n",
    "\n",
    "# for index, row in df_test.iterrows():\n",
    "#     print(row['title'])\n",
    "#     print(row['categoryName'])\n",
    "#     print(\"ORG:\" + row['original_text'])\n",
    "#     print(\"GPT:\" + row['gpt3_finetuned_v1'])\n",
    "#     print(\"GPT3.5:\" + row['gpt3.5_turbo'])\n",
    "#     print(\"__________________________________________________________________________________________\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jetzt tatsächliche Daten augmentiert / generiert. Dazu einen neuen Dataframe erstellen...\n",
    "\n",
    "Später wird der dann bemerged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_true = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "# df_finetune = pd.read_csv('dataset_ft_v3_en_mulitmod_pc.csv.csv')\n",
    "\n",
    "# # print(df_true['categoryName'].value_counts())\n",
    "# # print(df_finetune['categoryName'].value_counts())\n",
    "# print(f'True:' , df_true.shape)\n",
    "\n",
    "# df_fake = pd.DataFrame(columns=df_true.columns)\n",
    "# df_fake['categoryName'] = df_true['categoryName']\n",
    "# df_fake['label'] = 'FAKE'\n",
    "\n",
    "# # just for reference. Can be delted later on. \n",
    "# df_fake['reviewId'] = df_true['reviewId']\n",
    "# df_fake['title'] = df_true['title']\n",
    "# df_fake['text'] = df_true['text']\n",
    "# df_fake['placeId'] = df_true['placeId']\n",
    "\n",
    "# df_fake.to_csv('fake_base.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ab hier neue finetunes ausprobieren und unter neuer Version speichern. \n",
    " Wichtig! Spaltennamen ändern von gpt3_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v2331.csv')\n",
    "df_fake[\"prompt_v4\"] = \"A Google Maps review about a \" + df_fake[\"categoryName\"] + \". ###\"\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    df_fake.at[index, 'gpt3_v4'] = gpt3_finetuned(row)\n",
    "    print(df_fake.at[index, 'gpt3_v4'])\n",
    "    print(index)\n",
    "    if index % 50 == 0:\n",
    "        df_fake.to_csv('fake_base_gpt3_v23314.csv', index=False)\n",
    "        print(\"Wir warten ein paar Sekunden und hoffen, dass der API key deshalb nicht geblockt wird...\")\n",
    "        time.sleep(25)\n",
    "        print(\"Weiter geht's...\")\n",
    "\n",
    "print(\"Done with gpt3 text generation.\")\n",
    "print(df_fake.shape)\n",
    "print(df_fake.columns)\n",
    "\n",
    "df_fake.to_csv(\"fake_base_gpt3_v23314.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_fake and save in xlsx\n",
    "\n",
    "df_fake = pd.read_csv('fake_base_gpt3_v23314.csv')\n",
    "print(df_fake.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generierung\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereitung. Eine Sentiment-Analyse auf dem generierten Text durchführen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a sentiment analysis on the generated text gpt3_v2, gpt3_v3 gpt3_v3.1\n",
    "\n",
    "df_fake = pd.read_csv('fake_base_gpt3_v23314.csv')\n",
    "df_fake['sent_v2'] = np.nan\n",
    "df_fake['sent_v3']= np.nan\n",
    "df_fake['sent_v3.1'] = np.nan\n",
    "df_fake['sent_v4'] = np.nan\n",
    "\n",
    "df_fake['sent_v2'] = df_fake['gpt3_v 2'].astype(str)\n",
    "df_fake['sent_v3'] = df_fake['gpt3_v3'].astype(str)\n",
    "df_fake['sent_v3.1'] = df_fake['gpt3_v3.1'].astype(str)\n",
    "df_fake['sent_v4'] = df_fake['gpt3_v4'].astype(str)\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    print(\"Processing row: \", index)\n",
    "    try:\n",
    "        df_fake.at[index, 'sent_v2'] = sentiment_task(row['gpt3_v2'])[0]['label']\n",
    "        df_fake.at[index, 'sent_v3'] = sentiment_task(row['gpt3_v3'])[0]['label']\n",
    "        df_fake.at[index, 'sent_v3.1'] = sentiment_task(row['gpt3_v3.1'])[0]['label']\n",
    "        df_fake.at[index, 'sent_v4'] = sentiment_task(row['gpt3_v4'])[0]['label']\n",
    "    except RuntimeError:\n",
    "        print(\"Skipped due to messy data. Row: \", index)\n",
    "        pass\n",
    "\n",
    "df_fake.to_csv('fake_base_gpt3_v23314_sent.csv', index=False)\n",
    "df_fake.to_excel('fake_base_gpt3_v23314_sent.xlsx', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image: Dall-E-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"apikey_papa.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle_colReduced.csv.')\n",
    "print(df_fake.shape)\n",
    "print(df_fake.columns)\n",
    "print(df_fake['categoryName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of a nice visit at a water park taken by a photograph visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-SCV6Za0eWE7IV3ChY5Qs7Bsc/user-iQVPN2vt7WcRlK4vJDENOGMS/img-5ZcXkjyig9AQd9jPgp6SYPqm.png?st=2023-04-19T09%3A16%3A11Z&se=2023-04-19T11%3A16%3A11Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-04-19T08%3A50%3A31Z&ske=2023-04-20T08%3A50%3A31Z&sks=b&skv=2021-08-06&sig=oVRT9c6hNBE9%2B7fsaTLJSI5V0gI8TmHSGVCdtY5Zhq8%3D\n"
     ]
    }
   ],
   "source": [
    "def generate_dalle_prompt(row):\n",
    "    genre = row[\"genre\"].lower()\n",
    "    categoryName = row[\"categoryName\"].lower()\n",
    "    sentiment = row[\"sent_v4\"].lower()\n",
    "    locationString = f\"a {categoryName}\"\n",
    "    tone = \"\"\n",
    "    if sentiment == \"positive\":\n",
    "        sentiment = \"great\"\n",
    "        inspire_sentence = \"This photo is sure to delight and inspire anyone who sees it\"\n",
    "        if genre == \"restaurant\":\n",
    "            sentiment = \"delicious\"\n",
    "            tone = \"delicious, well-decorated\"\n",
    "        elif genre == \"hotel\":\n",
    "            sentiment = \"great\"\n",
    "            tone = \"nice\"\n",
    "        elif genre == \"activity\":\n",
    "            inspire_sentence = \"This photo is sure to inspire anyone who sees it to do the same activity.\"\n",
    "            sentiment = \"nice\"\n",
    "            tone = \"fun, happy athmosphere\"\n",
    "    elif sentiment == \"negative\":\n",
    "        inspire_sentence = \"This photo is likely to disappoint and demotivate anyone who sees it\"\n",
    "        sentiment = \"dissappointing\"\n",
    "        if genre == \"restaurant\":\n",
    "            tone = \"not very delicious, not very well-decorated\"\n",
    "        elif genre == \"hotel\":\n",
    "            tone = \"dirty, uncomfortable\"\n",
    "        elif genre == \"activity\":\n",
    "            tone = \"boring, lame\"\n",
    "    else:\n",
    "        inspire_sentence = \"\"\n",
    "        sentiment = \"average\"\n",
    "\n",
    "    if genre == \"restaurant\":\n",
    "        PROMPT =  f\"A photo of {sentiment} food at a {categoryName}. {inspire_sentence}. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, with settings of f/5.6, ISO 100, and a shutter speed of 1/200 sec. Close-up, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, a Review on Tripadvisor.com 2022\"\n",
    "    elif genre == \"hotel\":\n",
    "        PROMPT = f\"A photo of a {sentiment} stay at a {categoryName}, {inspire_sentence}. Sigma lens, wide shot, full shot. hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, a Review on Bookings.com in 2022\"\n",
    "    elif genre == \"activity\":\n",
    "        PROMPT = f\"A photo of a {sentiment} visit at a {categoryName} taken by a photograph visitor. From the point of view of a visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, a Review on Tripadvisor.com in 2022\"\n",
    "\n",
    "    print(PROMPT)\n",
    "    return PROMPT\n",
    "\n",
    "prompt = generate_dalle_prompt(df_fake.iloc[599])\n",
    "response = openai.Image.create(prompt=prompt, n=1, size=\"256x256\")\n",
    "print(response[\"data\"][0][\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "print(df_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(705, 44)\n",
      "Generating Promt for row:  0\n",
      "A photo of a nice visit at a amusement center taken by a photograph visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\n",
      "Generated Image for index:  0\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-SCV6Za0eWE7IV3ChY5Qs7Bsc/user-iQVPN2vt7WcRlK4vJDENOGMS/img-7v10dG4gFhLL51L6kCKgE3JG.png?st=2023-04-19T09%3A23%3A16Z&se=2023-04-19T11%3A23%3A16Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-04-19T08%3A31%3A15Z&ske=2023-04-20T08%3A31%3A15Z&sks=b&skv=2021-08-06&sig=mdfeYH/9UkpYRRY40svUk54Nvyyo1ELJWpf8HV9058Q%3D\n",
      "Saved Image for index:  0\n",
      "_______________________NOW START DOWNLOADING FOR INDEX 0 ____________________________________________________________________\n",
      "Downloading Image for index 0, reviewId ChZDSUhNMG9nS0VJQ0FnSURJanBQb1pBEAEF,...\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-SCV6Za0eWE7IV3ChY5Qs7Bsc/user-iQVPN2vt7WcRlK4vJDENOGMS/img-GEHEsI43vpspk7fAC2ffsosQ.png?st=2023-04-19T09%3A21%3A38Z&se=2023-04-19T11%3A21%3A38Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-04-19T08%3A51%3A20Z&ske=2023-04-20T08%3A51%3A20Z&sks=b&skv=2021-08-06&sig=8pkBc5f4XN1ZLlE%2BsSyzuX3BHdj7iP6xiTL4Rqsnu4U%3D\n",
      "RGB\n",
      "(256, 256)\n",
      "Saved Image for index:  0\n",
      "_______________________________DONE___________________________________________________________\n",
      "Generating Promt for row:  1\n",
      "A photo of a dissappointing visit at a amusement center taken by a photograph visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\n",
      "Generated Image for index:  1\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-SCV6Za0eWE7IV3ChY5Qs7Bsc/user-iQVPN2vt7WcRlK4vJDENOGMS/img-TFZDcGpaseTie2grTQXP15iE.png?st=2023-04-19T09%3A23%3A23Z&se=2023-04-19T11%3A23%3A23Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-04-19T08%3A15%3A26Z&ske=2023-04-20T08%3A15%3A26Z&sks=b&skv=2021-08-06&sig=bpfEzbqpbnqHJlH2xrUmbsULvRkMSEuZrrr4JoPvIyA%3D\n",
      "Saved Image for index:  1\n",
      "_______________________NOW START DOWNLOADING FOR INDEX 1 ____________________________________________________________________\n",
      "Downloading Image for index 1, reviewId ChdDSUhNMG9nS0VJQ0FnSUNZLWRHY3VRRRABF,...\n",
      "nan\n",
      "RGB\n",
      "(256, 256)\n",
      "Saved Image for index:  1\n",
      "_______________________________DONE___________________________________________________________\n",
      "Generating Promt for row:  2\n",
      "A photo of a nice visit at a amusement center taken by a photograph visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\n",
      "Generated Image for index:  2\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-SCV6Za0eWE7IV3ChY5Qs7Bsc/user-iQVPN2vt7WcRlK4vJDENOGMS/img-yXWQocaaYAy8LHyd0lWzPLjb.png?st=2023-04-19T09%3A23%3A30Z&se=2023-04-19T11%3A23%3A30Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-04-19T07%3A29%3A56Z&ske=2023-04-20T07%3A29%3A56Z&sks=b&skv=2021-08-06&sig=ECG2gFUJjQEY6IRkzW%2BNhaESZTnYVkiFAzbGIWFPfUo%3D\n",
      "Saved Image for index:  2\n",
      "_______________________NOW START DOWNLOADING FOR INDEX 2 ____________________________________________________________________\n",
      "Downloading Image for index 2, reviewId ChdDSUhNMG9nS0VJQ0FnSUNtc04zQXNRRRABF,...\n",
      "nan\n",
      "RGB\n",
      "(256, 256)\n",
      "Saved Image for index:  2\n",
      "_______________________________DONE___________________________________________________________\n",
      "Generating Promt for row:  3\n",
      "A photo of a nice visit at a amusement center taken by a photograph visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\n",
      "Generated Image for index:  3\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-SCV6Za0eWE7IV3ChY5Qs7Bsc/user-iQVPN2vt7WcRlK4vJDENOGMS/img-SZ1LeC6sMpFoiL4zThFUd6Ho.png?st=2023-04-19T09%3A23%3A37Z&se=2023-04-19T11%3A23%3A37Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-04-19T08%3A12%3A14Z&ske=2023-04-20T08%3A12%3A14Z&sks=b&skv=2021-08-06&sig=7AV33tAsaxdUZpF1R6Gex7E4kYPkcj%2BjutqRazezg9I%3D\n",
      "Saved Image for index:  3\n",
      "_______________________NOW START DOWNLOADING FOR INDEX 3 ____________________________________________________________________\n",
      "Downloading Image for index 3, reviewId ChZDSUhNMG9nS0VJQ0FnSUNvb05hU1pREAEF,...\n",
      "nan\n",
      "RGB\n",
      "(256, 256)\n",
      "Saved Image for index:  3\n",
      "_______________________________DONE___________________________________________________________\n",
      "Generating Promt for row:  4\n",
      "A photo of a nice visit at a amusement center taken by a photograph visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\n",
      "Generated Image for index:  4\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-SCV6Za0eWE7IV3ChY5Qs7Bsc/user-iQVPN2vt7WcRlK4vJDENOGMS/img-ACgv0buN6BCmdQenLV9EGyQI.png?st=2023-04-19T09%3A23%3A44Z&se=2023-04-19T11%3A23%3A44Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-04-19T07%3A48%3A40Z&ske=2023-04-20T07%3A48%3A40Z&sks=b&skv=2021-08-06&sig=5HiW68pWMfptqYTusCwQPPQCo6PVQ0N4LbfibiUeew4%3D\n",
      "Saved Image for index:  4\n",
      "_______________________NOW START DOWNLOADING FOR INDEX 4 ____________________________________________________________________\n",
      "Downloading Image for index 4, reviewId ChZDSUhNMG9nS0VJQ0FnSUQyazc3ZE53EAEF,...\n",
      "nan\n",
      "RGB\n",
      "(256, 256)\n",
      "Saved Image for index:  4\n",
      "_______________________________DONE___________________________________________________________\n",
      "Generating Promt for row:  5\n",
      "A photo of a nice visit at a amusement center taken by a photograph visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\n",
      "Generated Image for index:  5\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit exceeded for images per minute in organization org-SCV6Za0eWE7IV3ChY5Qs7Bsc. Limit: 5/1min. Current: 6/1min. Please visit https://help.openai.com/en/articles/6696591 to learn how to increase your rate limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m df_fake\u001b[39m.\u001b[39mat[index, \u001b[39m'\u001b[39m\u001b[39mdalle_prompt\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m prompt\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGenerated Image for index: \u001b[39m\u001b[39m\"\u001b[39m, index)\n\u001b[1;32m---> 14\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mImage\u001b[39m.\u001b[39;49mcreate(prompt\u001b[39m=\u001b[39;49mprompt, n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, size\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m256x256\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     15\u001b[0m df_fake\u001b[39m.\u001b[39mat[index, \u001b[39m'\u001b[39m\u001b[39mfake_reviewImageUrls/1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     16\u001b[0m response_url \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\michi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\api_resources\\image.py:36\u001b[0m, in \u001b[0;36mImage.create\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     26\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[0;32m     27\u001b[0m     api_key,\n\u001b[0;32m     28\u001b[0m     api_base\u001b[39m=\u001b[39mapi_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m _, api_version \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_api_type_and_version(api_type, api_version)\n\u001b[1;32m---> 36\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m     37\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_url(\u001b[39m\"\u001b[39;49m\u001b[39mgenerations\u001b[39;49m\u001b[39m\"\u001b[39;49m), params\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     41\u001b[0m     response, api_key, api_version, organization\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\michi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\michi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    624\u001b[0m         ),\n\u001b[0;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\michi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit exceeded for images per minute in organization org-SCV6Za0eWE7IV3ChY5Qs7Bsc. Limit: 5/1min. Current: 6/1min. Please visit https://help.openai.com/en/articles/6696591 to learn how to increase your rate limit."
     ]
    }
   ],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle_colReduced.csv')\n",
    "\n",
    "df_fake['reviewImageUrls/1'] = \"\"\n",
    "print(df_fake.shape)\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    if index%5==0:\n",
    "        print(\"Waiting due Tue API Limits\")\n",
    "        time.sleep(5) \n",
    "\n",
    "    if  index < 0:\n",
    "        print(\"Schon berechnet (auf anderem Account): \", index)\n",
    "        continue\n",
    "    print(\"Generating Promt for row: \", index)\n",
    "    prompt = generate_dalle_prompt(row)\n",
    "    df_fake.at[index, 'dalle_prompt'] = prompt\n",
    "    print(\"Generated Image for index: \", index)\n",
    "    response = openai.Image.create(prompt=prompt, n=1, size=\"256x256\")\n",
    "    df_fake.at[index, 'fake_reviewImageUrls/1'] = response[\"data\"][0][\"url\"]\n",
    "    response_url = response[\"data\"][0][\"url\"]\n",
    "    print(response[\"data\"][0][\"url\"])\n",
    "    df_fake.to_csv('fake_base_gpt3_v23314_sent_dalle_colReduced.csv', index=False)\n",
    "    print(\"Saved Image for index: \", index)\n",
    "    print(f\"_______________________NOW START DOWNLOADING FOR INDEX {index} ____________________________________________________________________\")\n",
    "    reviewId = row['reviewId']\n",
    "\n",
    "    print(f\"Downloading Image for index {index}, reviewId {reviewId},...\")\n",
    "    print(row['fake_reviewImageUrls/1'])\n",
    "    response = requests.get(response_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    print(img.mode)\n",
    "    print(img.size)\n",
    "    img.save(f'02_Images/fake_image_url_1/{index}_{reviewId}_fake_reviewImageUrls_1.png')\n",
    "    print(\"Saved Image for index: \", index)\n",
    "    print(\"_______________________________DONE___________________________________________________________\")\n",
    "\n",
    "print(\"Fertig mit Erzeugung von Bildern mit API über Dalle 2.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eveentuell die erzeugten Bilder umbennen, falls System was aus Filenamen lernt bzw es die Filenamen nicht mehr passen wegen dem zusammengeführten Index später\n",
    "\n",
    "...rename a file from folder fake_image_url_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in glob.glob('fake_image_url_0/*.png'):\n",
    "#     print(filename)\n",
    "#     os.rename(filename, filename[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "df_fake['githubUrls/0'] = \"\"\n",
    "print(df_fake.shape)\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    print(\"Generating Github Url for row: \", index)\n",
    "    github_path = f\"https://raw.githubusercontent.com/MichaelSeitz98/seminararbeit_review_detection/main/02_Images/fake_image_url_0/{index}_{row['reviewId']}_fake_reviewImageUrls_0.png\"\n",
    "    df_fake.at[index, 'githubUrls/0'] = github_path\n",
    "    print(f\"Generated {github_path} Github Url for index: \", index)\n",
    "\n",
    "print(\"Fertig mit Erzeugung von Github Urls.\")\n",
    "print(df_fake[\"githubUrls/0\"])\n",
    "\n",
    "#df_fake.to_csv('fake_base_gpt3_v23314_sent_dalle.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exkurs/Ausblick: Generierung der Dall-E-2-Prompt mit GPT3.5 Turbo\n",
    "\n",
    "Wird nochmals verbessern. Kombination sehr Powerfull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chatGPT:\n",
    "    def __init__(self, api_key, rolle):\n",
    "        openai.api_key = api_key\n",
    "        self.dialog = [{\"role\": \"system\", \"content\": rolle}]\n",
    "\n",
    "    def question(self, question):\n",
    "        self.dialog.append({\"role\": \"user\", \"content\": question})\n",
    "        ergebnis = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\", messages=self.dialog\n",
    "        )\n",
    "        antwort = ergebnis[\"choices\"][0].message.content\n",
    "        self.dialog.append({\"role\": \"assistant\", \"content\": antwort})\n",
    "        return antwort\n",
    "\n",
    "\n",
    "role = \"As a visitor who visited this place and took a quick photo for a Tripadvisor Review, very short sententces.\"\n",
    "prompt = \"Describe a photo of a hotel.The photo is taken by a visitor with its iPhone. Describe some details what could be on the photo inclusive detailed camera settings about lens and shutter speed.\"\n",
    "chatGPT(api_key, role).question(prompt)\n",
    "prompt_ret = print(chatGPT(api_key, role).question(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A photo about a hotel: The hotel photo taken with an iPhone shows the grand entrance with a fountain and valet service. The lens used is the standard iPhone camera lens with a focal length of 4.25mm. The shutter speed may be around 1/125 sec to capture the moving valet cars. The colors are vibrant and shadows are minimal due to the natural lighting.\"\n",
    "prompt +=  \"hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\"\n",
    "print(prompt)\n",
    "response = openai.Image.create(prompt=prompt, n=1, size=\"256x256\")\n",
    "print(response[\"data\"][0][\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle_colReduced.csv')\n",
    "print(df_fake[df_fake['sent_v3'] != df_fake['sent_v4']].shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulare Daten "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name und PublishedAtDate mit Faker erzeugt\n",
    "\n",
    "Fake publishedAtDate & publishedAt Column im Fake dataset and store it in column published_at_date_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "fake = Faker('en_GB')\n",
    "df_fake['fake_publishedAtDate'] = \"\"\n",
    "\n",
    "end_date = datetime(2023, 3, 29)\n",
    "start_date = end_date - timedelta(days=365*7)\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    fake_time = fake.date_time_between(start_date=start_date, end_date=end_date, tzinfo=None)\n",
    "    fake_time_str = fake_time.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    df_fake.at[index, 'fake_publishedAtDate'] = fake_time_str\n",
    "    print(f\"Generated {fake_time_str} for index: \", index)\n",
    "\n",
    "print(\"Fertig mit Erzeugung von fake publishedAtDate.\")\n",
    "print(df_fake[\"fake_publishedAtDate\"])\n",
    "df_fake.to_csv('fake_base_gpt3_v23314_sent_dalle.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namen auch mit Faker augmentiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "df_fake['fake_name'] = \"\"\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    fake_vorname = fake.first_name()\n",
    "    fake_nachname = fake.last_name()\n",
    "    fake_name = fake_vorname + \" \" + fake_nachname\n",
    "    df_fake.at[index, 'fake_name'] = fake_name\n",
    "    print(f\"Generated name for index {index}: {fake_name} \")\n",
    "\n",
    "df_fake.to_csv('fake_base_gpt3_v23314_sent_dalle.csv', index=False)\n",
    "print(f\"Fertig mit Erzeugung von fake name: {df_fake.shape}\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN for Tabular Data (stars, likesCount, reviewerNumberOfReviews, isLocalGuide)\n",
    "\n",
    "mit TabGAN oder CTGAN, eventuell "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereitung der tabularen GANs -> an diesem datensatz soll er sich orierntieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_tabGAN = pd.read_csv('01_Data/raw_data/dataset_für_weitere_forschung.csv')\n",
    "df_real = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "\n",
    "df_base_tabGAN.shape\n",
    "\n",
    "df_base_tabGAN = df_base_tabGAN[~df_base_tabGAN['reviewId'].isin(df_real['reviewId'])]\n",
    "df_base_tabGAN = df_base_tabGAN.dropn(subset=['reviewImageUrls/0'])\n",
    "\n",
    "print(df_base_tabGAN.shape)\n",
    "print(df_base_tabGAN.columns)\n",
    "\n",
    "df_base_tabGAN.to_csv('01_Data/raw_data/base_dataset_tabGAN.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oder soll ich einfach die base_keywords_sentiment_reduced.csv nehmen und darauf das TABGAN trainieren? Macht wsl mehr Sinn, dann ist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "df_real['reviewerNumberOfReviews'].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with CTGAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctgan\n",
    "from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_multimod = pd.read_csv('01_Data/raw_data/base_dataset_tabGAN.csv')\n",
    "\n",
    "print(df_all_multimod.shape)\n",
    "print(df_all_multimod['stars'].mean())\n",
    "df_all_multimod = df_all_multimod[['stars', 'likesCount', 'reviewerNumberOfReviews', 'isLocalGuide']]\n",
    "categorical_features = ['stars', 'likesCount', 'reviewerNumberOfReviews', 'isLocalGuide']\n",
    "\n",
    "train_data['stars'] = train_data['stars'].astype('category')\n",
    "train_data['likesCount'] = train_data['likesCount'].astype('float64')\n",
    "train_data['reviewerNumberOfReviews'] = train_data['reviewerNumberOfReviews'].astype('float64')\n",
    "train_data['isLocalGuide'] = train_data['isLocalGuide'].astype('category')\n",
    "\n",
    "categorical_features = ['stars', 'likesCount', 'reviewerNumberOfReviews', 'isLocalGuide']\n",
    "\n",
    "ctgan = CTGAN(verbose=True)\n",
    "ctgan.fit(df_all_multimod, categorical_features, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data = pd.read_csv('01_Data/raw_data/base_dataset_tabGAN.csv')\n",
    "\n",
    "samples = ctgan.sample(705)\n",
    "print(samples)\n",
    "\n",
    "print(f\"Fake Data mit mean (stars): {samples['stars'].mean()}\")\n",
    "print(f\"Orgi Data mit mean (stars): {org_data['stars'].mean()}\")\n",
    "print(f\"Fake Data mit mean (likesCount): {samples['likesCount'].mean()}\")\n",
    "print(f\"Orgi Data mit mean (likesCount): {org_data['likesCount'].mean()}\")\n",
    "print(f\"Fake Data mit mean (reviewerNumberOfReviews): {samples['reviewerNumberOfReviews'].mean()}\")\n",
    "print(f\"Orgi Data mit mean (reviewerNumberOfReviews): {org_data['reviewerNumberOfReviews'].mean()}\")\n",
    "print(f\"Fake Data mit mean (isLocalGuide): {samples['isLocalGuide'].mean()}\")\n",
    "print(f\"Orgi Data mit mean (isLocalGuide): {org_data['isLocalGuide'].mean()}\")\n",
    "\n",
    "samples.to_csv('01_Data/raw_data/fake_metadata_ctgan_stars_likes_reviewernr_localguide.csv', index=False)\n",
    "\n",
    "print(samples.shape)\n",
    "# how many numerical features are there \n",
    "\n",
    "# list dtypes \n",
    "print(samples.dtypes)\n",
    "print(samples.select_dtypes(include=['float64']).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from table_evaluator import TableEvaluator\n",
    "\n",
    "# drop the isLocalGuide column in both dataframes\n",
    "\n",
    "samples = pd.read_csv('01_Data/raw_data/fake_metadata_ctgan_stars_likes_reviewernr_localguide.csv')\n",
    "org_data = pd.read_csv('01_Data/raw_data/base_dataset_tabGAN.csv')\n",
    "cols_to_keep = ['stars', 'likesCount', 'reviewerNumberOfReviews', 'isLocalGuide']\n",
    "\n",
    "samples = samples[cols_to_keep]\n",
    "org_data = org_data[cols_to_keep]\n",
    "\n",
    "# convert to float64\n",
    "samples['stars'] = samples['stars'].astype('float64')\n",
    "samples['likesCount'] = samples['likesCount'].astype('float64')\n",
    "samples['reviewerNumberOfReviews'] = samples['reviewerNumberOfReviews'].astype('float64')\n",
    "\n",
    "org_data['stars'] = org_data['stars'].astype('float64')\n",
    "org_data['likesCount'] = org_data['likesCount'].astype('float64')\n",
    "org_data['reviewerNumberOfReviews'] = org_data['reviewerNumberOfReviews'].astype('float64')\n",
    "\n",
    "print(org_data.shape, samples.shape)\n",
    "cat_cols = ['isLocalGuide']\n",
    "\n",
    "print(samples.columns)\n",
    "table_evaluator = TableEvaluator(org_data, samples, cat_cols=cat_cols)\n",
    "\n",
    "figure = table_evaluator.visual_evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "samples = pd.read_csv('01_Data/raw_data/fake_metadata_ctgan_stars_likes_reviewernr_localguide.csv')\n",
    "print(df_fake.shape)\n",
    "print(samples.shape)\n",
    "\n",
    "df_fake['fake_likesCount'] = \"\"\n",
    "df_fake['fake_reviewerNumberOfReviews'] = \"\"\n",
    "df_fake['fake_isLocalGuide'] = \"\"\n",
    "df_fake['fake_stars'] = \"\"\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    print(f\"Hinzufügen der Fake-Meta-Daten zu Reihe {index}\")\n",
    "    df_fake.at[index, 'fake_likesCount'] = samples['likesCount'][index]\n",
    "    df_fake.at[index, 'fake_reviewerNumberOfReviews'] = samples['reviewerNumberOfReviews'][index]\n",
    "    df_fake.at[index, 'fake_isLocalGuide'] = samples['isLocalGuide'][index]\n",
    "    df_fake.at[index, 'fake_stars'] = samples['stars'][index]\n",
    "\n",
    "print(f\"Done! Shape: {df_fake.shape}\")\n",
    "#df_fake.to_csv('fake_base_gpt3_v23314_sent_dalle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "df_real = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "\n",
    "df_fake['org_stars'] = df_real['stars']\n",
    "df_fake['url'] = df_real['url']\n",
    "\n",
    "df_fake.to_csv('fake_base_gpt3_v23314_sent_dalle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"fake_base_gpt3_v23314_sent_dalle.csv\")\n",
    "\n",
    "df_fake = df_fake.drop(\n",
    "    columns=[\n",
    "        \"likesCount\",\n",
    "        \"reviewerNumberOfReviews\",\n",
    "        \"isLocalGuide\",\n",
    "        \"publishedAtDate\",\n",
    "        \"name\",\n",
    "        \"stars\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_fake = df_fake.rename(\n",
    "    columns={\n",
    "        \"fake_name\": \"name\",\n",
    "        \"fake_likesCount\": \"likesCount\",\n",
    "        \"fake_reviewerNumberOfReviews\": \"reviewerNumberOfReviews\",\n",
    "        \"fake_isLocalGuide\": \"isLocalGuide\",\n",
    "        \"fake_publishedAtDate\": \"publishedAtDate\",\n",
    "        \"fake_stars\": \"stars\",\n",
    "    }\n",
    ")\n",
    "df_fake = df_fake.drop(\n",
    "    columns=[\n",
    "        \"categories/0\",\n",
    "        \"categories/1\",\n",
    "        \"categories/2\",\n",
    "        \"categoryName.1\",\n",
    "        \"reviewsCount\",\n",
    "        \"scrapedAt\",\n",
    "        \"street\",\n",
    "        \"temporarilyClosed\",\n",
    "        \"subTitle\",\n",
    "        \"description\",\n",
    "        \"price\",\n",
    "        \"totalScore\",\n",
    "        \"state\",\n",
    "        \"text_length\",\n",
    "        \"website\",\n",
    "        \"keywords\",\n",
    "        \"keywords_only\",\n",
    "        \"sentiment\",\n",
    "        \"sent_score_0\",\n",
    "        \"reviewerId\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(df_fake.columns)\n",
    "print(df_fake.shape)\n",
    "print(df_fake.count())\n",
    "\n",
    "df_fake.to_csv(\"fake_base_gpt3_v23314_sent_dalle_colReduced.csv\", index=False)\n",
    "#df_fake.to_excel(\"fake_base_gpt3_v23314_sent_dalle_colReduced.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"fake_base_gpt3_v23314_sent_dalle_colReduced.csv\")\n",
    "fake = Faker('en_US')\n",
    "df_fake['stars'] = \"\"\n",
    "\n",
    "print(df_fake['sent_v4'].value_counts())\n",
    "print(df_fake['org_stars'].value_counts(sort=True))\n",
    "\n",
    "df_fake['stars'].mean() \n",
    "sentiment_to_stars = {\n",
    "    'positive': [5] * 80 + [4] * 20,\n",
    "    'neutral': range(2, 4),\n",
    "    'negative': range(0, 2)\n",
    "}\n",
    "\n",
    "df_fake['stars'] = df_fake.apply(lambda row: fake.random_element(sentiment_to_stars[row['sent_v4']]), axis=1)\n",
    "print(df_fake['stars'].value_counts(sort=False))\n",
    "print(df_fake['stars'].mean())\n",
    "\n",
    "df_fake.to_csv(\"fake_base_gpt3_v23314_sent_dalle_colReduced.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"fake_base_gpt3_v23314_sent_dalle_colReduced.csv\")\n",
    "\n",
    "# rename columns reviewImageUrls/0 to org_reviewImageUrls/0\n",
    "\n",
    "# df_fake = df_fake.rename(columns={\"reviewImageUrls/0\": \"org_reviewImageUrls/0\"})\n",
    "# df_fake = df_fake.rename(columns={\"reviewImageUrls/1\": \"org_reviewImageUrls/1\"})\n",
    "# df_fake = df_fake.rename(columns={\"reviewImageUrls/2\": \"org_reviewImageUrls/2\"})\n",
    "# df_fake = df_fake.rename(columns={\"reviewImageUrls/3\": \"org_reviewImageUrls/3\"})\n",
    "# df_fake = df_fake.rename(columns={\"githubUrls/0\": \"reviewImageUrls/0\"})\n",
    "\n",
    "# save again, with Index\n",
    "\n",
    "# rename the column reviewIdF to reviewId, but first change reveiwId to org_reviewId\n",
    "# df_fake = df_fake.rename(columns={\"reviewId\": \"org_reviewId\"})\n",
    "# df_fake = df_fake.rename(columns={\"reviewIdF\": \"reviewId\"})\n",
    "\n",
    "# renmae org_reviewImageUrls/0.1 to reviewImageUrls/0\n",
    "#df_fake = df_fake.rename(columns={\"org_reviewImageUrls/0.1\": \"reviewImageUrls/0\"})\n",
    "\n",
    "\n",
    "df_fake.to_csv(\"fake_base_gpt3_v23314_sent_dalle_colReduced.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zu einem Großen Datensatz zusammenführen -> dafür muss aber alles fertig sein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(705, 38)\n",
      "Index(['Unnamed: 0', 'org_text', 'title', 'org_reviewId', 'categoryName', 'org_reviewImageUrls/0', 'org_reviewImageUrls/1', 'org_reviewImageUrls/2', 'org_reviewImageUrls/3', 'reviewUrl', 'reviewerPhotoUrl', 'reviewerUrl', 'url', 'genre', 'label', 'placeId', 'prompt_v2', 'gpt3_v2', 'prompt_v3', 'gpt3_v3', 'gpt3_v3.1', 'prompt_v4', 'text', 'sent_v2', 'sent_v3', 'sent_v3.1', 'sent_v4', 'reviewId', 'dalle_prompt', 'reviewImageUrls/0', 'publishedAtDate', 'name', 'likesCount', 'reviewerNumberOfReviews', 'isLocalGuide', 'stars_ctgan', 'org_stars', 'stars'], dtype='object')\n",
      "(705, 47)\n",
      "Index(['stars', 'publishedAtDate', 'name', 'text', 'title', 'subTitle', 'description', 'price', 'totalScore', 'likesCount', 'isLocalGuide', 'reviewId', 'categoryName', 'reviewImageUrls/0', 'reviewImageUrls/1', 'reviewImageUrls/2', 'reviewImageUrls/3', 'reviewImageUrls/4', 'reviewImageUrls/5', 'reviewImageUrls/6', 'reviewImageUrls/7', 'reviewImageUrls/8', 'reviewImageUrls/9', 'reviewUrl', 'reviewerId', 'reviewerNumberOfReviews', 'reviewerPhotoUrl', 'reviewerUrl', 'reviewsCount', 'scrapedAt', 'state', 'street', 'temporarilyClosed', 'url', 'website', 'categories/0', 'categories/1', 'categories/2', 'categoryName.1', 'genre', 'keywords', 'keywords_only', 'sentiment', 'sent_score_0', 'label', 'placeId', 'text_length'], dtype='object')\n",
      "(1410, 56)\n",
      "Index(['index_fake', 'org_text', 'title', 'org_reviewId', 'categoryName', 'org_reviewImageUrls/0', 'org_reviewImageUrls/1', 'org_reviewImageUrls/2', 'org_reviewImageUrls/3', 'reviewUrl', 'reviewerPhotoUrl', 'reviewerUrl', 'url', 'genre', 'label', 'placeId', 'prompt_v2', 'gpt3_v2', 'prompt_v3', 'gpt3_v3', 'gpt3_v3.1', 'prompt_v4', 'text', 'sent_v2', 'sent_v3', 'sent_v3.1', 'sent_v4', 'reviewId', 'dalle_prompt', 'reviewImageUrls/0', 'publishedAtDate', 'name', 'likesCount', 'reviewerNumberOfReviews', 'isLocalGuide', 'stars_ctgan', 'org_stars', 'stars', 'subTitle', 'description', 'price', 'totalScore', 'reviewImageUrls/1', 'reviewImageUrls/2', 'reviewImageUrls/3', 'reviewerId', 'reviewsCount', 'state', 'street', 'temporarilyClosed', 'website', 'keywords', 'keywords_only', 'sentiment', 'sent_score_0', 'text_length'], dtype='object')\n",
      "1410\n",
      "1410\n",
      "1410\n",
      "1410\n",
      "1410\n",
      "1410\n",
      "1410\n",
      "Individuelle Texte: 1410\n",
      "Individuelle Labels: 2\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "df_fake = pd.read_csv(\"fake_base_gpt3_v23314_sent_dalle_colReduced.csv\")\n",
    "df_fake = df_fake.drop(\n",
    "    columns=[\"Unnamed: 0.1\", \"Unnamed: 0.1.1\", \"Unnamed: 0.1.1.1\", \"Unnamed: 0.1.1.1.1\"]\n",
    ")\n",
    "\n",
    "df_fake = df_fake.rename(columns={\"text\": \"org_text\"})\n",
    "df_fake = df_fake.rename(columns={\"gpt3_v4\": \"text\"})\n",
    "print(df_fake.shape)\n",
    "print(df_fake.columns)\n",
    "\n",
    "\n",
    "df_real = pd.read_csv(\"base_keywords_sentiment_reduced.csv\")\n",
    "print(df_real.shape)\n",
    "print(df_real.columns)\n",
    "\n",
    "\n",
    "\n",
    "df_both = pd.concat([df_fake, df_real], axis=0)\n",
    "df_both = df_both.drop(\n",
    "    columns=[\n",
    "        \"reviewImageUrls/4\",\n",
    "        \"reviewImageUrls/5\",\n",
    "        \"reviewImageUrls/6\",\n",
    "        \"reviewImageUrls/7\",\n",
    "        \"reviewImageUrls/8\",\n",
    "        \"reviewImageUrls/9\",\n",
    "    ]\n",
    ")\n",
    "df_both = df_both.drop(columns=[\"scrapedAt\"])\n",
    "df_both = df_both.drop(\n",
    "    columns=[\"categories/0\", \"categories/1\", \"categories/2\", \"categoryName.1\"]\n",
    ")\n",
    "df_both['label'] = df_both['label'].str.lower()\n",
    "df_both = df_both.rename(columns={'Unnamed: 0': 'index_fake'})\n",
    "\n",
    "print(df_both.shape)\n",
    "print(df_both.columns)\n",
    "print(df_both[\"reviewImageUrls/0\"].count())\n",
    "print(df_both[\"publishedAtDate\"].nunique())\n",
    "print(df_both[\"name\"].count())\n",
    "print(df_both[\"stars\"].count())\n",
    "print(df_both[\"likesCount\"].count())\n",
    "print(df_both[\"reviewerNumberOfReviews\"].count())\n",
    "print(df_both[\"isLocalGuide\"].count())\n",
    "print(f\"Individuelle Texte: {df_both['text'].nunique()}\")\n",
    "print(f\"Individuelle Labels: {df_both['label'].nunique()}\")\n",
    "\n",
    "df_both.to_csv(\"base_fake_real.csv\", index=False)\n",
    "df_both.to_excel(\"base_fake_real.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abad024bc45f6d7f9bfe9f2e5b4bbf3ee80d4a34082e6860f2ffd5f4e4e7895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
