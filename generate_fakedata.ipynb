{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from keybert import KeyBERT\n",
    "import langdetect\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os \n",
    "import glob\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "# model = KeyBERT('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"apikey_moritz.txt\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "print(api_key)\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text: Finetuned GPT3 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_list = openai.FineTune.list()\n",
    "fine_tuned_model = fine_tune_list['data'][0].fine_tuned_model\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"A Google Maps review about a steak house. ###\"\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=200, # Change amount of tokens for longer completion\n",
    "  temperature=1,\n",
    "  stop = \"END\"\n",
    ")\n",
    "print(answer['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_finetuned(row):\n",
    "    catgeoryName = row['categoryName'].lower()\n",
    "    prompt = \"A Google Maps review about a \" + catgeoryName + \". ###\"\n",
    "    print(prompt)\n",
    "    answer = openai.Completion.create(\n",
    "      model=fine_tuned_model,\n",
    "      prompt=prompt,\n",
    "      max_tokens=200, # Change amount of tokens for longer completion\n",
    "      temperature=1, \n",
    "      stop = \"END\"\n",
    "    )\n",
    "    return answer['choices'][0]['text']\n",
    "\n",
    "# def gpt3_5_turbo(row):\n",
    "#     prompt = \"Write a Google Maps review about a \" + row['categoryName'] + \". In Style of a Google user that writes a review about a place.\"\n",
    "#     role = \"In stlye of a google user that writes a review about a place.\"\n",
    "#     prompt = \"Write a Google Maps review about a \" + row['categoryName']+\".\"\n",
    "#     print(prompt)\n",
    "#     return chatGPT(api_key, role).question(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outdated: Nur für Test:  gpt3_5_turbo vs gpt3_finetuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## df_test.to_csv('test_df_showcase20gpt.csv')\n",
    "# # print(\"Done with gpt3_finetuned_v1 text generation.\")\n",
    "\n",
    "# df_test = pd.read_csv('test_df_showcase.csv')\n",
    "# df_test['gpt3_finetuned_v1'] = df_test.apply(gpt3_finetuned, axis=1)\n",
    "# df_test.to_csv('test_df_showcase.csv')\n",
    "# print(\"Done with gpt3.5_turbo text generation.\")\n",
    "\n",
    "# print(df_test)\n",
    "# print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('test_df_showcase.csv')\n",
    "# df_test['gpt3.5_turbo'] = df_test['gpt3.5_turbo'].astype(str)\n",
    "\n",
    "# for index, row in df_test.iterrows():\n",
    "#     print(row['title'])\n",
    "#     print(row['categoryName'])\n",
    "#     print(\"ORG:\" + row['original_text'])\n",
    "#     print(\"GPT:\" + row['gpt3_finetuned_v1'])\n",
    "#     print(\"GPT3.5:\" + row['gpt3.5_turbo'])\n",
    "#     print(\"__________________________________________________________________________________________\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jetzt tatsächliche Daten augmentiert / generiert. Dazu einen neuen Dataframe erstellen...\n",
    "\n",
    "Später wird der dann bemerged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_true = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "# df_finetune = pd.read_csv('dataset_ft_v3_en_mulitmod_pc.csv.csv')\n",
    "\n",
    "# # print(df_true['categoryName'].value_counts())\n",
    "# # print(df_finetune['categoryName'].value_counts())\n",
    "# print(f'True:' , df_true.shape)\n",
    "\n",
    "# df_fake = pd.DataFrame(columns=df_true.columns)\n",
    "# df_fake['categoryName'] = df_true['categoryName']\n",
    "# df_fake['label'] = 'FAKE'\n",
    "\n",
    "# # just for reference. Can be delted later on. \n",
    "# df_fake['reviewId'] = df_true['reviewId']\n",
    "# df_fake['title'] = df_true['title']\n",
    "# df_fake['text'] = df_true['text']\n",
    "# df_fake['placeId'] = df_true['placeId']\n",
    "\n",
    "# df_fake.to_csv('fake_base.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ab hier neue finetunes ausprobieren und unter neuer Version speichern. \n",
    " Wichtig! Spaltennamen ändern von gpt3_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('fake_base_gpt3_v2331.csv')\n",
    "df_real[\"prompt_v4\"] = \"A Google Maps review about a \" + df_real[\"categoryName\"] + \". ###\"\n",
    "\n",
    "for index, row in df_real.iterrows():\n",
    "    df_real.at[index, 'gpt3_v4'] = gpt3_finetuned(row)\n",
    "    print(df_real.at[index, 'gpt3_v4'])\n",
    "    print(index)\n",
    "    if index % 50 == 0:\n",
    "        df_real.to_csv('fake_base_gpt3_v23314.csv', index=False)\n",
    "        print(\"Wir warten ein paar Sekunden und hoffen, dass der API key deshalb nicht geblockt wird...\")\n",
    "        time.sleep(25)\n",
    "        print(\"Weiter geht's...\")\n",
    "\n",
    "print(\"Done with gpt3 text generation.\")\n",
    "print(df_real.shape)\n",
    "print(df_real.columns)\n",
    "\n",
    "df_real.to_csv(\"fake_base_gpt3_v23314.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_fake and save in xlsx\n",
    "\n",
    "df_real = pd.read_csv('fake_base_gpt3_v23314.csv')\n",
    "print(df_real.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generierung\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereitung. Eine Sentiment-Analyse auf dem generierten Text durchführen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a sentiment analysis on the generated text gpt3_v2, gpt3_v3 gpt3_v3.1\n",
    "\n",
    "df_real = pd.read_csv('fake_base_gpt3_v23314.csv')\n",
    "df_real['sent_v2'] = np.nan\n",
    "df_real['sent_v3']= np.nan\n",
    "df_real['sent_v3.1'] = np.nan\n",
    "df_real['sent_v4'] = np.nan\n",
    "\n",
    "df_real['sent_v2'] = df_real['gpt3_v2'].astype(str)\n",
    "df_real['sent_v3'] = df_real['gpt3_v3'].astype(str)\n",
    "df_real['sent_v3.1'] = df_real['gpt3_v3.1'].astype(str)\n",
    "df_real['sent_v4'] = df_real['gpt3_v4'].astype(str)\n",
    "\n",
    "for index, row in df_real.iterrows():\n",
    "    print(\"Processing row: \", index)\n",
    "    try:\n",
    "        df_real.at[index, 'sent_v2'] = sentiment_task(row['gpt3_v2'])[0]['label']\n",
    "        df_real.at[index, 'sent_v3'] = sentiment_task(row['gpt3_v3'])[0]['label']\n",
    "        df_real.at[index, 'sent_v3.1'] = sentiment_task(row['gpt3_v3.1'])[0]['label']\n",
    "        df_real.at[index, 'sent_v4'] = sentiment_task(row['gpt3_v4'])[0]['label']\n",
    "    except RuntimeError:\n",
    "        print(\"Skipped due to messy data. Row: \", index)\n",
    "        pass\n",
    "\n",
    "df_real.to_csv('fake_base_gpt3_v23314_sent.csv', index=False)\n",
    "df_real.to_excel('fake_base_gpt3_v23314_sent.xlsx', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image: Dall-E-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"apikey_papa.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('fake_base_gpt3_v23314_sent.csv')\n",
    "print(df_real.shape)\n",
    "print(df_real.columns)\n",
    "print(df_real['categoryName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dalle_prompt(row):\n",
    "    genre = row[\"genre\"].lower()\n",
    "    categoryName = row[\"categoryName\"].lower()\n",
    "    sentiment = row[\"sent_v4\"].lower()\n",
    "    locationString = f\"a {categoryName}\"\n",
    "    tone = \"\"\n",
    "    if sentiment == \"positive\":\n",
    "        sentiment = \"great\"\n",
    "        inspire_sentence = \"This photo is sure to delight and inspire anyone who sees it\"\n",
    "        if genre == \"restaurant\":\n",
    "            sentiment = \"delicious\"\n",
    "            tone = \"delicious, well-decorated\"\n",
    "        elif genre == \"hotel\":\n",
    "            sentiment = \"great\"\n",
    "            tone = \"clean\"\n",
    "        elif genre == \"activity\":\n",
    "            inspire_sentence = \"This photo is sure to inspire anyone who sees it to do the same activity.\"\n",
    "            sentiment = \"fun\"\n",
    "            tone = \"fun, happy athmosphere\"\n",
    "    elif sentiment == \"negative\":\n",
    "        inspire_sentence = \"This photo is likely to disappoint and demotivate anyone who sees it\"\n",
    "        sentiment = \"dissappointing\"\n",
    "        if genre == \"restaurant\":\n",
    "            tone = \"bad service, dirty, bad decoration\"\n",
    "        elif genre == \"hotel\":\n",
    "            tone = \"dirty, uncomfortable\"\n",
    "        elif genre == \"activity\":\n",
    "            tone = \"boring, lame\"\n",
    "    else:\n",
    "        inspire_sentence = \"\"\n",
    "        sentiment = \"average\"\n",
    "\n",
    "    if genre == \"restaurant\":\n",
    "       # PROMPT = f\"A makro of {sentiment} food at a {categoryName}, {tone}, {inspire_sentence}, Sigma 105mm F2.8, close-up, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\"\n",
    "        PROMPT =  f\"A photo of {sentiment} food at a {categoryName}. {inspire_sentence}. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, with settings of f/5.6, ISO 100, and a shutter speed of 1/200 sec. Close-up, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2,  on Tripadvisor.com 2022\"\n",
    "    elif genre == \"hotel\":\n",
    "        PROMPT = f\"A photo of {sentiment} stay at a {categoryName}, {inspire_sentence}. Sigma lens, wide shot, full shot. hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Bookings.com in 2022\"\n",
    "    elif genre == \"activity\":\n",
    "        PROMPT = f\"A photo of a {categoryName} taken by a photograph visitor. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\"\n",
    "\n",
    "    print(PROMPT)\n",
    "    return PROMPT\n",
    "\n",
    "prompt = generate_dalle_prompt(df_real.iloc[599])\n",
    "response = openai.Image.create(prompt=prompt, n=1, size=\"256x256\")\n",
    "print(response[\"data\"][0][\"url\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "print(df_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "\n",
    "df_real['fake_reviewImageUrls/0'] = \"\"\n",
    "print(df_real.shape)\n",
    "\n",
    "for index, row in df_real.iterrows():\n",
    "    if  index < 449:\n",
    "        print(\"Schon berechnet (auf anderem Account): \", index)\n",
    "        continue\n",
    "    print(\"Generating Promt for row: \", index)\n",
    "    prompt = generate_dalle_prompt(row)\n",
    "    df_real.at[index, 'dalle_prompt'] = prompt\n",
    "    print(\"Generated Image for index: \", index)\n",
    "    response = openai.Image.create(prompt=prompt, n=1, size=\"256x256\")\n",
    "    df_real.at[index, 'fake_reviewImageUrls/0'] = response[\"data\"][0][\"url\"]\n",
    "    response_url = response[\"data\"][0][\"url\"]\n",
    "    print(response[\"data\"][0][\"url\"])\n",
    "    df_real.to_csv('fake_base_gpt3_v23314_sent_dalle.csv', index=False)\n",
    "    print(\"Saved Image for index: \", index)\n",
    "    print(f\"_______________________NOW START DOWNLOADING FOR INDEX {index} ____________________________________________________________________\")\n",
    "    reviewId = row['reviewId']\n",
    "    reviewIdF = row['reviewIdF']\n",
    "    print(f\"Downloading Image for index {index}, reviewId {reviewId}, reviewIdF {reviewIdF}...\")\n",
    "    print(row['fake_reviewImageUrls/0'])\n",
    "    response = requests.get(response_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    print(img.mode)\n",
    "    print(img.size)\n",
    "    img.save(f'fake_image_url_0/{index}_{reviewId}_fake_reviewImageUrls_0.png')\n",
    "    print(\"Saved Image for index: \", index)\n",
    "    print(\"_______________________________DONE___________________________________________________________\")\n",
    "\n",
    "print(\"Fertig mit Erzeugung von Bildern mit API über Dalle 2.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eveentuell die erzeugten Bilder umbennen, falls System was aus Filenamen lernt bzw es die Filenamen nicht mehr passen wegen dem zusammengeführten Index später\n",
    "\n",
    "...rename a file from folder fake_image_url_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in glob.glob('fake_image_url_0/*.png'):\n",
    "#     print(filename)\n",
    "#     os.rename(filename, filename[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_real = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "df_real['githubUrls/0'] = \"\"\n",
    "print(df_real.shape)\n",
    "\n",
    "for index, row in df_real.iterrows():\n",
    "    print(\"Generating Github Url for row: \", index)\n",
    "    github_path = f\"https://raw.githubusercontent.com/MichaelSeitz98/seminararbeit_review_detection/main/02_Images/fake_image_url_0/{index}_{row['reviewId']}_fake_reviewImageUrls_0.png\"\n",
    "    df_real.at[index, 'githubUrls/0'] = github_path\n",
    "    print(f\"Generated {github_path} Github Url for index: \", index)\n",
    "\n",
    "print(\"Fertig mit Erzeugung von Github Urls.\")\n",
    "print(df_real[\"githubUrls/0\"])\n",
    "\n",
    "df_real.to_csv('fake_base_gpt3_v23314_sent_dalle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('fake_base_gpt3_v23314_sent_dalle.csv')\n",
    "print(df_real.columns)\n",
    "df_real.to_excel('fake_base_gpt3_v23314_sent_dalle.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulare Daten "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake publishedAtDate & publishedAt Column im Fake dataset and store it in column published_at_date_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "\n",
    "print(df_real['publishedAtDate'].min())\n",
    "print(df_real['publishedAtDate'].max())\n",
    "end_date = datetime(2023, 3, 30)\n",
    "start_date = end_date - timedelta(days=365*7)\n",
    "\n",
    "fake_time = fake.date_time_between(start_date=start_date, end_date=end_date, tzinfo=None)\n",
    "fake_time_str = fake_time.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "print(fake_time_str)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake the name column with faker and store it in column name of df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "likesCount, reviewerNumberOfReviews, isLocalGuide mit TabGAN oder CTGAN erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abad024bc45f6d7f9bfe9f2e5b4bbf3ee80d4a34082e6860f2ffd5f4e4e7895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
