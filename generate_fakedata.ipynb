{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai \n",
    "from keybert import KeyBERT\n",
    "import langdetect\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "\n",
    "# model = KeyBERT('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"apikey_mama.txt\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "print(api_key)\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text: Finetuned GPT3 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_list = openai.FineTune.list()\n",
    "fine_tuned_model = fine_tune_list['data'][1].fine_tuned_model\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"A Google Maps review about a hotel. ###\"\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=250, # Change amount of tokens for longer completion\n",
    "  temperature=1,\n",
    "  stop = \"END\"\n",
    ")\n",
    "print(answer['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_finetuned(row):\n",
    "    catgeoryName = row['categoryName'].lower()\n",
    "    prompt = \"A Google Maps review about a \" + catgeoryName + \". ###\"\n",
    "    print(prompt)\n",
    "    answer = openai.Completion.create(\n",
    "      model=fine_tuned_model,\n",
    "      prompt=prompt,\n",
    "      max_tokens=200, # Change amount of tokens for longer completion\n",
    "      temperature=1, \n",
    "      stop = \"END\"\n",
    "    )\n",
    "    return answer['choices'][0]['text']\n",
    "\n",
    "# def gpt3_5_turbo(row):\n",
    "#     prompt = \"Write a Google Maps review about a \" + row['categoryName'] + \". In Style of a Google user that writes a review about a place.\"\n",
    "#     role = \"In stlye of a google user that writes a review about a place.\"\n",
    "#     prompt = \"Write a Google Maps review about a \" + row['categoryName']+\".\"\n",
    "#     print(prompt)\n",
    "#     return chatGPT(api_key, role).question(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outdated: Nur für Test:  gpt3_5_turbo vs gpt3_finetuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## df_test.to_csv('test_df_showcase20gpt.csv')\n",
    "# # print(\"Done with gpt3_finetuned_v1 text generation.\")\n",
    "\n",
    "# df_test = pd.read_csv('test_df_showcase.csv')\n",
    "# df_test['gpt3_finetuned_v1'] = df_test.apply(gpt3_finetuned, axis=1)\n",
    "# df_test.to_csv('test_df_showcase.csv')\n",
    "# print(\"Done with gpt3.5_turbo text generation.\")\n",
    "\n",
    "# print(df_test)\n",
    "# print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('test_df_showcase.csv')\n",
    "# df_test['gpt3.5_turbo'] = df_test['gpt3.5_turbo'].astype(str)\n",
    "\n",
    "# for index, row in df_test.iterrows():\n",
    "#     print(row['title'])\n",
    "#     print(row['categoryName'])\n",
    "#     print(\"ORG:\" + row['original_text'])\n",
    "#     print(\"GPT:\" + row['gpt3_finetuned_v1'])\n",
    "#     print(\"GPT3.5:\" + row['gpt3.5_turbo'])\n",
    "#     print(\"__________________________________________________________________________________________\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jetzt tatsächliche Daten augmentiert / generiert. Dazu einen neuen Dataframe erstellen...\n",
    "\n",
    "Später wird der dann bemerged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_true = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "# df_finetune = pd.read_csv('dataset_ft_v3_en_mulitmod_pc.csv.csv')\n",
    "\n",
    "# # print(df_true['categoryName'].value_counts())\n",
    "# # print(df_finetune['categoryName'].value_counts())\n",
    "# print(f'True:' , df_true.shape)\n",
    "\n",
    "# df_fake = pd.DataFrame(columns=df_true.columns)\n",
    "# df_fake['categoryName'] = df_true['categoryName']\n",
    "# df_fake['label'] = 'FAKE'\n",
    "\n",
    "# # just for reference. Can be delted later on. \n",
    "# df_fake['reviewId'] = df_true['reviewId']\n",
    "# df_fake['title'] = df_true['title']\n",
    "# df_fake['text'] = df_true['text']\n",
    "# df_fake['placeId'] = df_true['placeId']\n",
    "\n",
    "# df_fake.to_csv('fake_base.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ab hier neue finetunes ausprobieren und unter neuer Version speichern. \n",
    " Wichtig! Spaltennamen ändern von gpt3_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v2331.csv')\n",
    "df_fake[\"prompt_v3\"] = \"A Google Maps review about a \" + df_fake[\"categoryName\"] + \". ###\"\n",
    "\n",
    "# but only from row 550 on \n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    if index < 550:\n",
    "        print(\"We skip this row, because it was already processed.\")\n",
    "        print(index)\n",
    "        print(\"print(df_fake.at[index, 'gpt3_v3.1'])\")\n",
    "        continue\n",
    "    df_fake.at[index, 'gpt3_v3.1'] = gpt3_finetuned(row)\n",
    "    print(df_fake.at[index, 'gpt3_v3.1'])\n",
    "    print(index)\n",
    "    if index % 50 == 0:\n",
    "        df_fake.to_csv('fake_base_gpt3_v2331.csv', index=False)\n",
    "        print(\"Wir warten ein paar Sekunden und hoffen, dass der API key deshalb nicht geblockt wird...\")\n",
    "        time.sleep(20)\n",
    "        print(\"Weiter geht's...\")\n",
    "\n",
    "print(\"Done with gpt3 text generation.\")\n",
    "print(df_fake.shape)\n",
    "print(df_fake.columns)\n",
    "\n",
    "df_fake.to_csv(\"fake_base_gpt3_v2331.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(705, 52)\n"
     ]
    }
   ],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v2331.csv')\n",
    "print(df_fake.shape)\n",
    "df_fake.rename(columns={'text_gpt3_v2': 'gpt3_v2'}, inplace=True)\n",
    "df_fake.to_csv('fake_base_gpt3_v2331.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generierung\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereitung. Eine Sentiment-Analyse auf dem generierten Text durchführen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a sentiment analysis on the generated text gpt3_v2, gpt3_v3 gpt3_v3.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image: Dall-E-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-HItbdseOerJ031NWpBTmNR3B/user-2DO6BdaWO7ZVLzbvJNZoM0La/img-Aa4vgo5NSteLXsIDQHMVXRyI.png?st=2023-04-07T13%3A06%3A26Z&se=2023-04-07T15%3A06%3A26Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-04-06T20%3A44%3A31Z&ske=2023-04-07T20%3A44%3A31Z&sks=b&skv=2021-08-06&sig=J1vluMX%2BzdTL6aCPdPzQt8iADlI829cZudcZX0%2B8QDo%3D\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"Photo of disgusting experience at a hotel, photography, high resolution, 4k, many details\"\n",
    "\n",
    "with open(\"apikey_mama.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read()\n",
    "\n",
    "response = openai.Image.create(\n",
    "    prompt=PROMPT,\n",
    "    n=2,\n",
    "    size=\"256x256\",\n",
    ")\n",
    "\n",
    "print(response[\"data\"][0][\"url\"])\n",
    "\n",
    "with open(\"02_Visualizations\\dalle-2-tries.txt\", \"a\") as f:\n",
    "    f.write(\"\\nPROMPT \" + PROMPT +\": \" + response[\"data\"][0][\"url\"] + \" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image: Tries with StableDiffusion aka Dreamstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
    "\n",
    "os.environ['STABILITY_HOST'] = 'grpc.stability.ai:443'\n",
    "\n",
    "with open('dreamstudio.txt', 'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "os.environ['STABILITY_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_api = client.StabilityInference(\n",
    "    key=os.environ['STABILITY_KEY'], # API Key reference.\n",
    "    verbose=True, # Print debug messages.\n",
    "    engine=\"stable-diffusion-512-v2-1\", # Set the engine to use for generation.\n",
    "    # Available engines: stable-diffusion-v1 stable-diffusion-v1-5 stable-diffusion-512-v2-0 stable-diffusion-768-v2-0\n",
    "    # stable-diffusion-512-v2-1 stable-diffusion-768-v2-1 stable-inpainting-v1-0 stable-inpainting-512-v2-0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our initial generation parameters.\n",
    "answers = stability_api.generate(\n",
    "    prompt=\"Bad experience at italien restaurant,high quality photography, 4k, close-up\",\n",
    "    #seed=992446758, # If a seed is provided, the resulting generated image will be deterministic.\n",
    "                    # What this means is that as long as all generation parameters remain the same, you can always recall the same image simply by generating it again.\n",
    "                    # Note: This isn't quite the case for Clip Guided generations, which we'll tackle in a future example notebook.\n",
    "    steps=30, # Amount of inference steps performed on image generation. Defaults to 30.\n",
    "    cfg_scale=7.0, # Influences how strongly your generation is guided to match your prompt.\n",
    "                   # Setting this value higher increases the strength in which it tries to match your prompt.\n",
    "                   # Defaults to 7.0 if not specified.\n",
    "    width=512, # Generation width, defaults to 512 if not included.\n",
    "    height=512, # Generation height, defaults to 512 if not included.\n",
    "    samples=2, # Number of images to generate, defaults to 1 if not included.\n",
    "    sampler=generation.SAMPLER_K_DPMPP_2M # Choose which sampler we want to denoise our generation with.\n",
    "                                                 # Defaults to k_dpmpp_2m if not specified. Clip Guidance only supports ancestral samplers.\n",
    "                                                 # (Available Samplers: ddim, plms, k_euler, k_euler_ancestral, k_heun, k_dpm_2, k_dpm_2_ancestral, k_dpmpp_2s_ancestral, k_lms, k_dpmpp_2m)\n",
    ")\n",
    "\n",
    "# Set up our warning to print to the console if the adult content classifier is tripped.\n",
    "# If adult content classifier is not tripped, save generated images.\n",
    "for resp in answers:\n",
    "    for artifact in resp.artifacts:\n",
    "        if artifact.finish_reason == generation.FILTER:\n",
    "            warnings.warn(\n",
    "                \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                \"Please modify the prompt and try again.\")\n",
    "        if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "            img = Image.open(io.BytesIO(artifact.binary))\n",
    "            img.save(str(artifact.seed)+ \".png\") # Save our generated images with their seed number as the filename."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text: ChatGPT3.5 Turbo Verworfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chatGPT: \n",
    "    def __init__(self, api_key, rolle):\n",
    "        openai.api_key = api_key\n",
    "        self.dialog = [{\"role\":\"system\", \"content\":rolle}]\n",
    "\n",
    "    def question(self, question):\n",
    "        self.dialog.append({\"role\":\"user\", \"content\":question})\n",
    "        ergebnis = openai.ChatCompletion.create(model='gpt-3.5-turbo', messages=self.dialog)\n",
    "        antwort = ergebnis[\"choices\"][0].message.content\n",
    "        self.dialog.append({\"role\":\"assistant\", \"content\":antwort})\n",
    "        return antwort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"In stlye of a google user that writes a review about a place he or she visited.\"\n",
    "prompt = \"Write a Google Maps review about a bowling alley with max 200 tokens.\"\n",
    "chatGPT(api_key, role).question(prompt)\n",
    "print(chatGPT(api_key, role).question(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(text):\n",
    "    keywords = model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=5)\n",
    "    keywords = [keyword[0] for keyword in keywords]\n",
    "    return keywords\n",
    "\n",
    "output_string= \"I recently visited the Italian Restaurant and overall had a great experience. The atmosphere was cozy and inviting with a classic Italian vibe. The staff was friendly and attentive, making sure we had everything we needed throughout our meal.The menu had a great selection of traditional Italian dishes and some unique options as well. I tried the gnocchi and it was delicious, perfectly cooked with a flavorful sauce. My friend had the lasagna and said it was some of the best she's ever had. The only downside was the wait time for our table, as we had to wait about 30 minutes even though we had reservations. However, the food and service made up for it. Overall, I would recommend the Italian Restaurant to anyone who loves Italian cuisine and wants to have a nice, cozy dinner out with friends or family.\"\n",
    "keywords = get_keywords(output_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abad024bc45f6d7f9bfe9f2e5b4bbf3ee80d4a34082e6860f2ffd5f4e4e7895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
