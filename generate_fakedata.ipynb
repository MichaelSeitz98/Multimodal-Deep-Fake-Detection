{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai \n",
    "from keybert import KeyBERT\n",
    "import langdetect\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "\n",
    "# model = KeyBERT('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"apikey_moritz.txt\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "print(api_key)\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text: Finetuned GPT3 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_list = openai.FineTune.list()\n",
    "fine_tuned_model = fine_tune_list['data'][0].fine_tuned_model\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"A Google Maps review about a steak house. ###\"\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=200, # Change amount of tokens for longer completion\n",
    "  temperature=1,\n",
    "  stop = \"END\"\n",
    ")\n",
    "print(answer['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_finetuned(row):\n",
    "    catgeoryName = row['categoryName'].lower()\n",
    "    prompt = \"A Google Maps review about a \" + catgeoryName + \". ###\"\n",
    "    print(prompt)\n",
    "    answer = openai.Completion.create(\n",
    "      model=fine_tuned_model,\n",
    "      prompt=prompt,\n",
    "      max_tokens=200, # Change amount of tokens for longer completion\n",
    "      temperature=1, \n",
    "      stop = \"END\"\n",
    "    )\n",
    "    return answer['choices'][0]['text']\n",
    "\n",
    "# def gpt3_5_turbo(row):\n",
    "#     prompt = \"Write a Google Maps review about a \" + row['categoryName'] + \". In Style of a Google user that writes a review about a place.\"\n",
    "#     role = \"In stlye of a google user that writes a review about a place.\"\n",
    "#     prompt = \"Write a Google Maps review about a \" + row['categoryName']+\".\"\n",
    "#     print(prompt)\n",
    "#     return chatGPT(api_key, role).question(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outdated: Nur für Test:  gpt3_5_turbo vs gpt3_finetuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## df_test.to_csv('test_df_showcase20gpt.csv')\n",
    "# # print(\"Done with gpt3_finetuned_v1 text generation.\")\n",
    "\n",
    "# df_test = pd.read_csv('test_df_showcase.csv')\n",
    "# df_test['gpt3_finetuned_v1'] = df_test.apply(gpt3_finetuned, axis=1)\n",
    "# df_test.to_csv('test_df_showcase.csv')\n",
    "# print(\"Done with gpt3.5_turbo text generation.\")\n",
    "\n",
    "# print(df_test)\n",
    "# print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('test_df_showcase.csv')\n",
    "# df_test['gpt3.5_turbo'] = df_test['gpt3.5_turbo'].astype(str)\n",
    "\n",
    "# for index, row in df_test.iterrows():\n",
    "#     print(row['title'])\n",
    "#     print(row['categoryName'])\n",
    "#     print(\"ORG:\" + row['original_text'])\n",
    "#     print(\"GPT:\" + row['gpt3_finetuned_v1'])\n",
    "#     print(\"GPT3.5:\" + row['gpt3.5_turbo'])\n",
    "#     print(\"__________________________________________________________________________________________\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jetzt tatsächliche Daten augmentiert / generiert. Dazu einen neuen Dataframe erstellen...\n",
    "\n",
    "Später wird der dann bemerged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_true = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "# df_finetune = pd.read_csv('dataset_ft_v3_en_mulitmod_pc.csv.csv')\n",
    "\n",
    "# # print(df_true['categoryName'].value_counts())\n",
    "# # print(df_finetune['categoryName'].value_counts())\n",
    "# print(f'True:' , df_true.shape)\n",
    "\n",
    "# df_fake = pd.DataFrame(columns=df_true.columns)\n",
    "# df_fake['categoryName'] = df_true['categoryName']\n",
    "# df_fake['label'] = 'FAKE'\n",
    "\n",
    "# # just for reference. Can be delted later on. \n",
    "# df_fake['reviewId'] = df_true['reviewId']\n",
    "# df_fake['title'] = df_true['title']\n",
    "# df_fake['text'] = df_true['text']\n",
    "# df_fake['placeId'] = df_true['placeId']\n",
    "\n",
    "# df_fake.to_csv('fake_base.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ab hier neue finetunes ausprobieren und unter neuer Version speichern. \n",
    " Wichtig! Spaltennamen ändern von gpt3_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v2331.csv')\n",
    "df_fake[\"prompt_v4\"] = \"A Google Maps review about a \" + df_fake[\"categoryName\"] + \". ###\"\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    df_fake.at[index, 'gpt3_v4'] = gpt3_finetuned(row)\n",
    "    print(df_fake.at[index, 'gpt3_v4'])\n",
    "    print(index)\n",
    "    if index % 50 == 0:\n",
    "        df_fake.to_csv('fake_base_gpt3_v23314.csv', index=False)\n",
    "        print(\"Wir warten ein paar Sekunden und hoffen, dass der API key deshalb nicht geblockt wird...\")\n",
    "        time.sleep(25)\n",
    "        print(\"Weiter geht's...\")\n",
    "\n",
    "print(\"Done with gpt3 text generation.\")\n",
    "print(df_fake.shape)\n",
    "print(df_fake.columns)\n",
    "\n",
    "df_fake.to_csv(\"fake_base_gpt3_v23314.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_fake and save in xlsx\n",
    "\n",
    "df_fake = pd.read_csv('fake_base_gpt3_v23314.csv')\n",
    "print(df_fake.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generierung\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereitung. Eine Sentiment-Analyse auf dem generierten Text durchführen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a sentiment analysis on the generated text gpt3_v2, gpt3_v3 gpt3_v3.1\n",
    "\n",
    "df_fake = pd.read_csv('fake_base_gpt3_v23314.csv')\n",
    "df_fake['sent_v2'] = np.nan\n",
    "df_fake['sent_v3']= np.nan\n",
    "df_fake['sent_v3.1'] = np.nan\n",
    "df_fake['sent_v4'] = np.nan\n",
    "\n",
    "df_fake['sent_v2'] = df_fake['gpt3_v2'].astype(str)\n",
    "df_fake['sent_v3'] = df_fake['gpt3_v3'].astype(str)\n",
    "df_fake['sent_v3.1'] = df_fake['gpt3_v3.1'].astype(str)\n",
    "df_fake['sent_v4'] = df_fake['gpt3_v4'].astype(str)\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    print(\"Processing row: \", index)\n",
    "    try:\n",
    "        df_fake.at[index, 'sent_v2'] = sentiment_task(row['gpt3_v2'])[0]['label']\n",
    "        df_fake.at[index, 'sent_v3'] = sentiment_task(row['gpt3_v3'])[0]['label']\n",
    "        df_fake.at[index, 'sent_v3.1'] = sentiment_task(row['gpt3_v3.1'])[0]['label']\n",
    "        df_fake.at[index, 'sent_v4'] = sentiment_task(row['gpt3_v4'])[0]['label']\n",
    "    except RuntimeError:\n",
    "        print(\"Skipped due to messy data. Row: \", index)\n",
    "        pass\n",
    "\n",
    "df_fake.to_csv('fake_base_gpt3_v23314_sent.csv', index=False)\n",
    "df_fake.to_excel('fake_base_gpt3_v23314_sent.xlsx', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image: Dall-E-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"apikey_juli.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent.csv')\n",
    "print(df_fake.shape)\n",
    "print(df_fake.columns)\n",
    "print(df_fake['categoryName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dalle_prompt(row):\n",
    "    genre = row[\"genre\"].lower()\n",
    "    categoryName = row[\"categoryName\"].lower()\n",
    "    sentiment = row[\"sent_v4\"].lower()\n",
    "    locationString = f\"a {categoryName}\"\n",
    "    tone = \"\"\n",
    "    if sentiment == \"positive\":\n",
    "        sentiment = \"great\"\n",
    "        inspire_sentence = \"This photo is sure to delight and inspire anyone who sees it\"\n",
    "        if genre == \"restaurant\":\n",
    "            sentiment = \"delicious\"\n",
    "            tone = \"delicious, well-decorated\"\n",
    "        elif genre == \"hotel\":\n",
    "            sentiment = \"great\"\n",
    "            tone = \"clean\"\n",
    "        elif genre == \"activity\":\n",
    "            inspire_sentence = \"This photo is sure to inspire anyone who sees it to do the same activity.\"\n",
    "            sentiment = \"fun\"\n",
    "            tone = \"fun, happy athmosphere\"\n",
    "    elif sentiment == \"negative\":\n",
    "        inspire_sentence = \"This photo is likely to disappoint and demotivate anyone who sees it\"\n",
    "        sentiment = \"dissappointing\"\n",
    "        if genre == \"restaurant\":\n",
    "            tone = \"bad service, dirty, bad decoration\"\n",
    "        elif genre == \"hotel\":\n",
    "            tone = \"dirty, uncomfortable\"\n",
    "        elif genre == \"activity\":\n",
    "            tone = \"boring, lame\"\n",
    "    else:\n",
    "        inspire_sentence = \"\"\n",
    "        sentiment = \"average\"\n",
    "\n",
    "    if genre == \"restaurant\":\n",
    "        PROMPT = f\"A photo of {sentiment} food at a {categoryName}, {tone}, {inspire_sentence}, Sigma 105mm F2.8, close-up, hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\"\n",
    "        PROMPT =  f\"A photo of {sentiment} food at a {categoryName}. {inspire_sentence}. The shot is taken with a Canon EOS 5D Mark IV camera and a 40mm f/1.8 lens, with settings of f/5.6, ISO 100, and a shutter speed of 1/200 sec. Close-up, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2,  on Tripadvisor.com 2022\"\n",
    "    elif genre == \"hotel\":\n",
    "        PROMPT = f\"A photo of {sentiment} stay at a {categoryName}, {inspire_sentence}. Sigma lens, wide shot, full shot. hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Bookings.com in 2022\"\n",
    "    elif genre == \"activity\":\n",
    "        PROMPT = f\"A photo  of a {categoryName}, {inspire_sentence} wide shot, Sigma 55mm F2.8,  hyper detailed, Super-Resolution, UHD, DTM, HDR, 8K --ar 4:3 --q 2, on Tripadvisor.com in 2022\"\n",
    "\n",
    "    print(PROMPT)\n",
    "    return PROMPT\n",
    "\n",
    "prompt = generate_dalle_prompt(df_fake.iloc[599])\n",
    "response = openai.Image.create(prompt=prompt, n=1, size=\"256x256\")\n",
    "print(response[\"data\"][0][\"url\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent.csv')\n",
    "df_fake['dalle_prompt'] = np.nan\n",
    "\n",
    "for index, row in df_fake.iterrows():\n",
    "    print(\"Generating Promt for row: \", index)\n",
    "    prompt = generate_dalle_prompt(row)\n",
    "    df_fake.at[index, 'dalle_prompt'] = prompt\n",
    "    print(\"Generated Image for index: \", index)\n",
    "    response = openai.Image.create(prompt=prompt, n=1, size=\"256x256\")\n",
    "    df_fake.at[index, 'fake_reviewImageUrls/0'] = response[\"data\"][0][\"url\"]\n",
    "    df_fake.to_csv('fake_base_gpt3_v23314_sent_dalle.csv', index=False)\n",
    "    print(\"Saved Image for index: \", index)\n",
    "    print(\"___________________________________________________________________________________________\")\n",
    "\n",
    "print(\"Fertig mit Erzeugung von Bildern mit Dalle 2.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download von Bildern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "response = requests.get(\"https://lh5.googleusercontent.com/p/AF1QipNf-ZejrPdXHfis5MCtO6kxNxIwa4s5MwyOxxwj=w256-h256-p-k-no\")\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img = img.convert(\"RGBA\")\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "img.save('test.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anderer Ansatz, variationen von bestehenenden, echten Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_base_gpt3_v23314_sent.csv')\n",
    "\n",
    "\n",
    "response = openai.Image.create_variation(\n",
    "     image=open(\"test.png\", \"rb\"),\n",
    "    n=2,\n",
    "     size=\"256x256\",\n",
    "    ) \n",
    "\n",
    "print(response[\"data\"][0][\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"A high quality photo of a disgusting experience at a hotel, photography, high resolution, 4k, many details\"\n",
    "\n",
    "with open(\"apikey_mama.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read()\n",
    "\n",
    "response = openai.Image.create(\n",
    "    prompt=PROMPT,\n",
    "    n=2,\n",
    "    size=\"256x256\",\n",
    ")\n",
    "\n",
    "print(response[\"data\"][0][\"url\"])\n",
    "\n",
    "with open(\"02_Visualizations\\dalle-2-tries.txt\", \"a\") as f:\n",
    "    f.write(\"\\nPROMPT \" + PROMPT +\": \" + response[\"data\"][0][\"url\"] + \" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text (OUTDATED) ChatGPT3.5 Turbo Verworfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chatGPT: \n",
    "    def __init__(self, api_key, rolle):\n",
    "        openai.api_key = api_key\n",
    "        self.dialog = [{\"role\":\"system\", \"content\":rolle}]\n",
    "\n",
    "    def question(self, question):\n",
    "        self.dialog.append({\"role\":\"user\", \"content\":question})\n",
    "        ergebnis = openai.ChatCompletion.create(model='gpt-3.5-turbo', messages=self.dialog)\n",
    "        antwort = ergebnis[\"choices\"][0].message.content\n",
    "        self.dialog.append({\"role\":\"assistant\", \"content\":antwort})\n",
    "        return antwort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"In stlye of a google user that writes a review about a place he or she visited.\"\n",
    "prompt = \"Write a Google Maps review about a bowling alley with max 200 tokens.\"\n",
    "chatGPT(api_key, role).question(prompt)\n",
    "print(chatGPT(api_key, role).question(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(text):\n",
    "    keywords = model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=5)\n",
    "    keywords = [keyword[0] for keyword in keywords]\n",
    "    return keywords\n",
    "\n",
    "output_string= \"I recently visited the Italian Restaurant and overall had a great experience. The atmosphere was cozy and inviting with a classic Italian vibe. The staff was friendly and attentive, making sure we had everything we needed throughout our meal.The menu had a great selection of traditional Italian dishes and some unique options as well. I tried the gnocchi and it was delicious, perfectly cooked with a flavorful sauce. My friend had the lasagna and said it was some of the best she's ever had. The only downside was the wait time for our table, as we had to wait about 30 minutes even though we had reservations. However, the food and service made up for it. Overall, I would recommend the Italian Restaurant to anyone who loves Italian cuisine and wants to have a nice, cozy dinner out with friends or family.\"\n",
    "keywords = get_keywords(output_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abad024bc45f6d7f9bfe9f2e5b4bbf3ee80d4a34082e6860f2ffd5f4e4e7895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
