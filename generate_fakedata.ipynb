{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook wird aus dem Dataset base_keywords_sentimement mit entsprechenden multimodalen Deep-Fakes erg√§nzt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_keywords_sentiment_reduced.csv')\n",
    "\n",
    "print(df.head())\n",
    "# print the keywords_only for the first 20 rows\n",
    "\n",
    "# add a new column which states the lengtth in words in column text\n",
    "df['text_length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# print the text_length, text and keywords_only for the first 20 rows\n",
    "df[['text_length', 'text', 'keywords_only']].head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text:  GPT 3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt3.5_api.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "class chatGPT: \n",
    "    def __init__(self, api_key, rolle):\n",
    "        openai.api_key = api_key\n",
    "        self.dialog = [{\"role\":\"system\", \"content\":rolle}]\n",
    "\n",
    "    def question(self, frage):\n",
    "        self.dialog.append({\"role\":\"user\", \"content\":frage})\n",
    "        ergebnis = openai.ChatCompletion.create(model='gpt-3.5-turbo', messages=self.dialog)\n",
    "        antwort = ergebnis[\"choices\"][0].message.content\n",
    "        self.dialog.append({\"role\":\"assistant\", \"content\":antwort})\n",
    "        return antwort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recently visited the Italian Restaurant in Texas and I have to say, it was an amazing experience! From the moment I walked in, the atmosphere was warm and welcoming with beautiful decor and lively music. The staff were incredibly friendly and knowledgeable about the menu, and they went out of their way to make us feel comfortable.\n",
      "\n",
      "As for the food, it was absolutely outstanding. I ordered the spaghetti carbonara and it was hands-down the best I've ever had. The noodles were perfectly cooked and the sauce was the perfect combination of creamy and savory. My companion ordered the veal Milanese and was equally impressed - the meat was tender and flavorful, and the portion size was generous.\n",
      "\n",
      "To top it off, the wine list was impressive and featured a broad selection of Italian and American wines. Our server recommended a lovely Chianti that perfectly complemented our meal.\n",
      "\n",
      "Overall, I would highly recommend this Italian Restaurant to anyone looking for an exceptional dining experience. The quality of the food, the exceptional service, and the cozy atmosphere make it a must-visit spot for Italian food lovers. 5 stars!\n"
     ]
    }
   ],
   "source": [
    "role = \"In stlye of a google user that writes a review about a place.\"\n",
    "prompt = \"Write a review about the Italien Restaurant about some of the keywords:\"\n",
    "chatGPT(api_key, role).question(prompt)\n",
    "\n",
    "print(chatGPT(api_key, role).question(prompt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image: Dall - E - 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"Photo of a nice experience at Bowling alley, photography, high quality, high resolution, 4k\"\n",
    "\n",
    "with open(\"dalleapi.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read()\n",
    "\n",
    "response = openai.Image.create(\n",
    "    prompt=PROMPT,\n",
    "    n=2,\n",
    "    size=\"256x256\",\n",
    ")\n",
    "\n",
    "# write the url to the image to the file: 02_Visualizations\\dalle-2-tries.txt as new line\n",
    "print(response[\"data\"][0][\"url\"])\n",
    "#save the image to the file: 02_Visualizations\\dalle-2-tries.txt as new line in txt file\n",
    "\n",
    "with open(\"02_Visualizations\\dalle-2-tries.txt\", \"a\") as f:\n",
    "    f.write(\"\\nPROMPT \" + PROMPT +\": \" + response[\"data\"][0][\"url\"] + \" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tries with StableDiffusion aka Dreamstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
    "\n",
    "# Our Host URL should not be prepended with \"https\" nor should it have a trailing slash.\n",
    "os.environ['STABILITY_HOST'] = 'grpc.stability.ai:443'\n",
    "\n",
    "# read the api key from draeamsudio.txt\n",
    "\n",
    "with open('dreamstudio.txt', 'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "os.environ['STABILITY_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_api = client.StabilityInference(\n",
    "    key=os.environ['STABILITY_KEY'], # API Key reference.\n",
    "    verbose=True, # Print debug messages.\n",
    "    engine=\"stable-diffusion-512-v2-1\", # Set the engine to use for generation.\n",
    "    # Available engines: stable-diffusion-v1 stable-diffusion-v1-5 stable-diffusion-512-v2-0 stable-diffusion-768-v2-0\n",
    "    # stable-diffusion-512-v2-1 stable-diffusion-768-v2-1 stable-inpainting-v1-0 stable-inpainting-512-v2-0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our initial generation parameters.\n",
    "answers = stability_api.generate(\n",
    "    prompt=\"Bad experience at italien restaurant,high quality photography, 4k, close-up\",\n",
    "    #seed=992446758, # If a seed is provided, the resulting generated image will be deterministic.\n",
    "                    # What this means is that as long as all generation parameters remain the same, you can always recall the same image simply by generating it again.\n",
    "                    # Note: This isn't quite the case for Clip Guided generations, which we'll tackle in a future example notebook.\n",
    "    steps=30, # Amount of inference steps performed on image generation. Defaults to 30.\n",
    "    cfg_scale=7.0, # Influences how strongly your generation is guided to match your prompt.\n",
    "                   # Setting this value higher increases the strength in which it tries to match your prompt.\n",
    "                   # Defaults to 7.0 if not specified.\n",
    "    width=512, # Generation width, defaults to 512 if not included.\n",
    "    height=512, # Generation height, defaults to 512 if not included.\n",
    "    samples=2, # Number of images to generate, defaults to 1 if not included.\n",
    "    sampler=generation.SAMPLER_K_DPMPP_2M # Choose which sampler we want to denoise our generation with.\n",
    "                                                 # Defaults to k_dpmpp_2m if not specified. Clip Guidance only supports ancestral samplers.\n",
    "                                                 # (Available Samplers: ddim, plms, k_euler, k_euler_ancestral, k_heun, k_dpm_2, k_dpm_2_ancestral, k_dpmpp_2s_ancestral, k_lms, k_dpmpp_2m)\n",
    ")\n",
    "\n",
    "# Set up our warning to print to the console if the adult content classifier is tripped.\n",
    "# If adult content classifier is not tripped, save generated images.\n",
    "for resp in answers:\n",
    "    for artifact in resp.artifacts:\n",
    "        if artifact.finish_reason == generation.FILTER:\n",
    "            warnings.warn(\n",
    "                \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                \"Please modify the prompt and try again.\")\n",
    "        if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "            img = Image.open(io.BytesIO(artifact.binary))\n",
    "            img.save(str(artifact.seed)+ \".png\") # Save our generated images with their seed number as the filename."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
