{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56483e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27d4ed",
   "metadata": {},
   "source": [
    "# How to fine-tune a GPT-3 model for specific prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b56a7b0",
   "metadata": {},
   "source": [
    "I'm constantly looking for ways to automate the work with support requests. An idea has been to fine-tune a GPT-3 model to answer common support-related questions.\n",
    "\n",
    "**Here's how you can fine-tune a GPT-3 model with Python with your own data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f831ab",
   "metadata": {},
   "source": [
    "In this walkthrough, we'll fine-tune a GPT-3 model to answer common support-related questions.\n",
    "\n",
    "Detailed step-by-step intructions for this repo in this blog post: https://norahsakal.com/blog/fine-tune-gpt3-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102018b",
   "metadata": {},
   "source": [
    ">### Disclaimer\n",
    ">This guide walks you through fine-tuning a GPT-3 model in Python, shown in a Jupyter notebook.\n",
    ">If you're looking for the steps of fine-tuning right in a terminal, [OpenAI has a great guide for fine-tuning in your terminal](https://beta.openai.com/docs/guides/fine-tuning \"fine-tuning in terminal\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f669e",
   "metadata": {},
   "source": [
    "# Define OpenAI API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaff120",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key =\"YOUR_OPENAI_API_KEY\"\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f08dd7",
   "metadata": {},
   "source": [
    "# Create training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f0c1f",
   "metadata": {},
   "source": [
    "Make sure to end each `prompt` with a suffix. According to the [OpenAI API reference](https://beta.openai.com/docs/guides/fine-tuning \"fine-tuning reference\"), you can use ` ->`.\n",
    "\n",
    "Also, make sure to end each `completion` with a suffix as well; I'm using `.\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5904b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = [{\n",
    "    \"prompt\": \"Prompt ->\",\n",
    "    \"completion\": \" Ideal answer.\\n\"\n",
    "},{\n",
    "    \"prompt\":\"Prompt ->\",\n",
    "    \"completion\": \" Ideal answer.\\n\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10cb45e",
   "metadata": {},
   "source": [
    "# Save dict as JSONL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ed465",
   "metadata": {},
   "source": [
    "Training data need to be a JSONL document.\n",
    "JSONL file is a newline-delimited JSON file.\n",
    "More info about JSONL: https://jsonlines.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4bc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"training_data.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as outfile:\n",
    "    for entry in data_file:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf169e",
   "metadata": {},
   "source": [
    "# Check JSONL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fe452",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f training_data.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923b02a",
   "metadata": {},
   "source": [
    "# Upload file to your OpenAI account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_response = openai.File.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb4254",
   "metadata": {},
   "source": [
    "# Save file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93469f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = upload_response.id\n",
    "file_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1007a6",
   "metadata": {},
   "source": [
    "# Fine-tune a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2da9b",
   "metadata": {},
   "source": [
    "The default model is **Curie**. \n",
    "\n",
    "If you'd like to use **DaVinci** instead, then add it as a base model to fine-tune:\n",
    "\n",
    "```openai.FineTune.create(training_file=file_id, model=\"davinci\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_response = openai.FineTune.create(training_file=file_id)\n",
    "fine_tune_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059b2b3",
   "metadata": {},
   "source": [
    "# Check fine-tune progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7fda90",
   "metadata": {},
   "source": [
    "Check the progress with `openai.FineTune.list_events(id=fine_tune_response.id)` and get a list of all the fine-tuning events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf062ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_events = openai.FineTune.list_events(id=fine_tune_response.id)\n",
    "fine_tune_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f5bf3",
   "metadata": {},
   "source": [
    "Check the progress with `openai.FineTune.retrieve(id=fine_tune_response.id)` and get an object with the fine-tuning job data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01831be",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_response = openai.FineTune.retrieve(id=fine_tune_response.id)\n",
    "retrieve_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e846ed",
   "metadata": {},
   "source": [
    "# Save fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca86136",
   "metadata": {},
   "source": [
    "### Troubleshooting fine_tuned_model as null\n",
    "During the fine-tuning process, the **fine_tuned_model** key may not be immediately available in the fine_tune_response object returned by `openai.FineTune.create()`.\n",
    "\n",
    "To check the status of your fine-tuning process, you can call the `openai.FineTune.retrieve()` function and pass in the **fine_tune_response.id**. This function will return a JSON object with information about the training status, such as the current epoch, the current batch, the training loss, and the validation loss.\n",
    "\n",
    "After the fine-tuning process is complete, you can check the status of all your fine-tuned models by calling `openai.FineTune.list()`. This will list all of your fine-tunes and their current status.\n",
    "\n",
    "Once the fine-tuning process is complete, you can retrieve the fine_tuned_model key by calling the `openai.FineTune.retrieve()` function again and passing in the fine_tune_response.id. This will return a JSON object with the key fine_tuned_model and the ID of the fine-tuned model that you can use for further completions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a071cb90",
   "metadata": {},
   "source": [
    "### Option 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e760b",
   "metadata": {},
   "source": [
    "If `fine_tune_response.fine_tuned_model != None` then the key **fine_tuned_model** is availble from the fine_tune_response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0616dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune_response.fine_tuned_model != None:\n",
    "    fine_tuned_model = fine_tune_response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34613188",
   "metadata": {},
   "source": [
    "### Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635655e",
   "metadata": {},
   "source": [
    "If `fine_tune_response.fine_tuned_model == None:` you can get the **fine_tuned_model** by listing all fine-tune events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune_response.fine_tuned_model == None:\n",
    "    fine_tune_list = openai.FineTune.list()\n",
    "    fine_tuned_model = fine_tune_list['data'][0].fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d0d25",
   "metadata": {},
   "source": [
    "### Option 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13537bb",
   "metadata": {},
   "source": [
    "If `fine_tune_response.fine_tuned_model == None:` you can get the **fine_tuned_model** key by retrieving the fine-tune job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune_response.fine_tuned_model == None:\n",
    "    fine_tuned_model = openai.FineTune.retrieve(id=fine_tune_response.id).fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601df11",
   "metadata": {},
   "source": [
    "# Test the new model on a new prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654268c",
   "metadata": {},
   "source": [
    "Remember to end the prompt with the same suffix as we used in the training data; ` ->`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cfb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"NEW PROMPT ->\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee69cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=10, # Change amount of tokens for longer completion\n",
    "  temperature=0\n",
    ")\n",
    "answer['choices'][0]['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
