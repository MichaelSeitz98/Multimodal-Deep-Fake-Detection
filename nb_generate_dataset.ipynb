{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageTk\n",
    "from faker import Faker\n",
    "from transformers import pipeline\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(model='all-mpnet-base-v2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Dataset erstellen\n",
    "\n",
    "3 Kategorien: Hotels, Restaurants & Aktivitäten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rest = pd.read_csv('01_Data\\dataset_Google-Maps-Reviews-Restaurants_2023-03-26_09-43-08-320.csv')\n",
    "df_act = pd.read_csv('01_Data\\dataset_Google-Maps-Reviews-Activities_2023-03-26_11-08-15-435.csv')\n",
    "df_hotel = pd.read_csv('01_Data\\dataset_Google-Maps-Reviews-Hotels_2023-03-26_11-34-16-492.csv')\n",
    "\n",
    "print('Restaurants (Shape): ', df_rest.shape)\n",
    "print('Activities (Shape): ', df_act.shape)\n",
    "print('Hotels (Shape): ', df_hotel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"stars\",\n",
    "    \"publishedAtDate\",\n",
    "    \"name\",\n",
    "    \"text\",\n",
    "    \"title\",\n",
    "    \"subTitle\",\n",
    "    \"description\",\n",
    "    \"price\",\n",
    "    \"totalScore\",\n",
    "    \"likesCount\",\n",
    "    \"isLocalGuide\",\n",
    "    \"reviewId\",\n",
    "    \"categoryName\",\n",
    "    \"reviewImageUrls/0\",\n",
    "    \"reviewImageUrls/1\",\n",
    "    \"reviewImageUrls/2\",\n",
    "    \"reviewImageUrls/3\",\n",
    "    \"reviewImageUrls/4\",\n",
    "    \"reviewImageUrls/5\",\n",
    "    \"reviewImageUrls/6\",\n",
    "    \"reviewImageUrls/7\",\n",
    "    \"reviewImageUrls/8\",\n",
    "    \"reviewImageUrls/9\",\n",
    "    \"reviewUrl\",\n",
    "    \"reviewerId\",\n",
    "    \"reviewerNumberOfReviews\",\n",
    "    \"reviewerPhotoUrl\",\n",
    "    \"reviewerUrl\",\n",
    "    \"reviewsCount\",\n",
    "    \"scrapedAt\",\n",
    "    \"state\",\n",
    "    \"street\",\n",
    "    \"temporarilyClosed\",\n",
    "    \"url\",\n",
    "    \"website\",\n",
    "    \"placeId\",\n",
    "    \"updatesFromCustomers/language\",\n",
    "    \n",
    "    \"categories/0\",\n",
    "    \"categories/1\",\n",
    "    \"categories/2\",\n",
    "    \"categoryName\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weiter mit Basic Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rest = df_rest.dropna(subset=[\"reviewImageUrls/0\"])\n",
    "df_rest = df_rest[columns_to_keep]\n",
    "print(df_rest['placeId'].nunique())\n",
    "df_rest['genre'] = 'restaurant'\n",
    "print(df_rest.shape)\n",
    "\n",
    "df_act = df_act.dropna(subset=[\"reviewImageUrls/0\"])\n",
    "df_act = df_act[columns_to_keep]\n",
    "print(df_act['placeId'].nunique())\n",
    "df_act['genre'] = 'activity'\n",
    "print(df_act.shape)\n",
    "\n",
    "df_hotel = df_hotel.dropna(subset=[\"reviewImageUrls/0\"])\n",
    "print(df_hotel['placeId'].nunique())\n",
    "df_hotel = df_hotel[columns_to_keep]\n",
    "df_hotel['genre'] = 'hotel'\n",
    "print(df_hotel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rest, df_act, df_hotel], ignore_index=True)\n",
    "print(df.shape)\n",
    "df.to_csv('all_rest_act_hotel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nur benötigt um für nachträgliches anhängen der placeId and Schlagwörter und Sentiment Dataframe\n",
    "\n",
    "# df_raw = pd.read_csv('all_rest_act_hotel.csv')\n",
    "# df_keywords = pd.read_csv('01_Data/archiv/base_keywords_sentiment_outdated_ohnePlaceId.csv')\n",
    "\n",
    "# df_keywords['placeId'] = df_keywords['name'].apply(lambda x: df_raw[df_raw['name'] == x]['placeId'].values[0])\n",
    "# print(df_keywords.shape)\n",
    "\n",
    "# df_keywords.to_csv('base_keywords_sentiment.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing the images to 256-256 pixels via getting the better url & cheaper for Dall-E-API Nutzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls_cols = [\n",
    "    \"reviewImageUrls/0\",\n",
    "    \"reviewImageUrls/1\",\n",
    "    \"reviewImageUrls/2\",\n",
    "    \"reviewImageUrls/3\",\n",
    "    \"reviewImageUrls/4\",\n",
    "    \"reviewImageUrls/5\",\n",
    "    \"reviewImageUrls/6\",\n",
    "    \"reviewImageUrls/7\",\n",
    "    \"reviewImageUrls/8\",\n",
    "    \"reviewImageUrls/9\"\n",
    "]\n",
    "\n",
    "for col in image_urls_cols:\n",
    "    df[col] = df[col].str.replace(\"=w150-h150-k-no-p\", \"=w256-h256-p-k-no\")\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Keywords With KeyBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('all_rest_act_hotel.csv').head(20)\n",
    "# df['text'] = df['text'].astype(str)\n",
    "# # print(\"Convertion done.\")\n",
    "\n",
    "# df['keywords'] = df['text'].apply(lambda x: kw_model.extract_keywords(x,keyphrase_ngram_range=(1,2) ,\n",
    "#                                      stop_words='english', \n",
    "#                                      highlight=False,\n",
    "#                                      top_n=5))\n",
    "# print(\"Keywords extraction done.\")\n",
    "# df.to_csv('base_keywords_sentiment_v2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "# sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('base_keywords_sentiment.csv')\n",
    "# df['sentiment'] = np.nan\n",
    "# df['sentiment'] = df['sentiment'].astype(str)\n",
    "# df['text'] = df['text'].astype(str)\n",
    "# df['sent_score_0'] = np.nan\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     try: \n",
    "#         print(\"Processing row: \", idx)\n",
    "#         sentiment = sentiment_task(row['text'])\n",
    "#         df.at[idx, 'sentiment'] = sentiment\n",
    "#     except RuntimeError:\n",
    "#         print(\"Skipped due to messy data. Row: \", idx)\n",
    "#         pass\n",
    "# df.to_csv('base_keywords_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only store the keywords in a list not the scores\n",
    "\n",
    "# df['keywords_only'] = df['keywords'].apply(lambda x: [i[0] for i in x])\n",
    "# print(df['keywords_only'])\n",
    "# df.to_csv('base_keywords_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_neu = pd.read_csv('base_keywords_sentiment.csv')\n",
    "# df_neu['sentiment'] = df_neu['sentiment'].astype(str)\n",
    "# df_neu.to_csv('base_keywords_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'] = 'real'\n",
    "# print(df.shape)\n",
    "# df.to_csv('base_keywords_sentiment.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kleineren Datensatz mit circa 750 Bildern erstellen aus Kostengründen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_keywords_sentiment.csv')\n",
    "print(df.shape)\n",
    "df = df[df['keywords_only'] != \"['nan']\"]\n",
    "print(df.shape)\n",
    "df.to_csv('base_keywords_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_keywords_sentiment.csv')\n",
    "print(df['stars'].mean())\n",
    "print(df.shape)\n",
    "df = df.sort_values(by=['stars'], ascending=True)\n",
    "df = df.groupby('placeId').apply(lambda x: x.sample(n=14,random_state = 2) if len(x) > 14 else x)\n",
    "print(df.shape)\n",
    "print(df['placeId'].nunique())\n",
    "\n",
    "print(df['stars'].value_counts().sort_index())\n",
    "print(df['stars'].mean())\n",
    "print(df['genre'].value_counts())\n",
    "\n",
    "df.to_csv('real_base_sent_reduced.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiserungen des Basis Datensatzes für Verständnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls_cols = [\n",
    "    \"reviewImageUrls/0\",\n",
    "    \"reviewImageUrls/1\",\n",
    "    \"reviewImageUrls/2\",\n",
    "    \"reviewImageUrls/3\",\n",
    "    \"reviewImageUrls/4\",\n",
    "    \"reviewImageUrls/5\",\n",
    "    \"reviewImageUrls/6\",\n",
    "    \"reviewImageUrls/7\",\n",
    "    \"reviewImageUrls/8\",\n",
    "    \"reviewImageUrls/9\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_keywords_sentiment.csv')\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "word_count_avg = df['text'].str.split().apply(len).mean()\n",
    "print(\"Average Review Length (Words): \", word_count_avg.round(1))\n",
    "\n",
    "word_count_tot = df['text'].str.split().apply(len).sum()\n",
    "print(\"Total Word Count: \" ,  word_count_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of Stars')\n",
    "plt.xlabel('Stars')\n",
    "#plt.savefig('stars_distribution.svg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "df['genre'].value_counts().plot(kind='bar') \n",
    "plt.title('Distribution of Genre')\n",
    "plt.xlabel('Genre')\n",
    "#plt.savefig('count_reviews_by_genre.svg')\n",
    "plt.show()\n",
    "\n",
    "df.groupby('genre')['stars'].mean().plot(kind='bar')\n",
    "for i, v in enumerate(df.groupby('genre')['stars'].mean().round(2)):\n",
    "    plt.text(i, v, str(v), color='black')\n",
    "\n",
    "plt.title('Average Star Rating by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Average Star Rating')\n",
    "# plt.savefig('average_star_rating_by_genre.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abad024bc45f6d7f9bfe9f2e5b4bbf3ee80d4a34082e6860f2ffd5f4e4e7895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
