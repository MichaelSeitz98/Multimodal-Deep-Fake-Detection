{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook wird der Datensatz base_fake_real.csv verwendet und untersucht wie man Fake-Reviews von Echten Reviews unterscheiden kann. Zuerst wird der Datensatz so vorbeietet um Features zu generieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\michi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\michi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\michi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\michi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import urllib\n",
    "from fastai.vision.all import *\n",
    "from fastdownload import download_url\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "import emoji\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import string\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import *\n",
    "\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensatz für Feature Extraction zu feature_base.csv vorbereitet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"base_fake_real.csv\")\n",
    "print(f\"Base Datensatz: {df.shape}\")\n",
    "# print(df.columns)\n",
    "\n",
    "df.drop(\n",
    "    [\n",
    "        \"index_fake\",\n",
    "        \"org_text\",\n",
    "        \"org_stars\",\n",
    "        \"sent_score_0\",\n",
    "        \"sent_v2\",\n",
    "        \"sent_v3\",\n",
    "        \"sent_v3.1\",\n",
    "        \"prompt_v3\",\n",
    "        \"website\",\n",
    "        \"dalle_prompt\",\n",
    "        \"website\",\n",
    "        \"prompt_v2\",\n",
    "        \"gpt3_v2\",\n",
    "        \"gpt3_v3\",\n",
    "        \"gpt3_v3.1\",\n",
    "        \"prompt_v4\",\n",
    "        \"org_reviewId\",\n",
    "        \"sent_v4\",\n",
    "        \"keywords\",\n",
    "        \"keywords_only\",\n",
    "        \"text_length\",\n",
    "        \"reviewImageUrls/3\",\n",
    "        \"reviewerPhotoUrl\",\n",
    "        \"reviewerUrl\",\n",
    "        \"reviewerId\",\n",
    "        \"temporarilyClosed\",\n",
    "        \"reviewsCount\",\n",
    "        \"street\",\n",
    "        \"state\",\n",
    "        \"totalScore\",\n",
    "        \"subTitle\",\n",
    "        \"description\",\n",
    "        \"price\",\n",
    "        \"sentiment\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df = df.reindex(\n",
    "    columns=[\n",
    "        \"label\",\n",
    "        \"reviewId\",\n",
    "        \"placeId\",\n",
    "        \"reviewUrl\",\n",
    "        \"url\",\n",
    "        \"title\",\n",
    "        \"categoryName\",\n",
    "        \"genre\",\n",
    "        \"text\",\n",
    "        \"stars\",\n",
    "        \"publishedAtDate\",\n",
    "        \"likesCount\",\n",
    "        \"name\",\n",
    "        \"isLocalGuide\",\n",
    "        \"reviewerNumberOfReviews\",\n",
    "        \"reviewImageUrls/0\",\n",
    "        \"reviewImageUrls/1\",\n",
    "        \"reviewImageUrls/2\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Reduzierter Datensatz als neue Basis für FE: {df.shape}\")\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "\n",
    "df.to_csv(\"base_features.csv\", index=False)\n",
    "df.to_excel(\"base_features.xlsx\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular: Feature Generierung\n",
    "\n",
    "1. aus publishedAt das bestmögliche rausholen\n",
    "\n",
    "when_on_day_4hbin:\n",
    "Midnight: 0-4 hours\n",
    "Early morning: 4-8 hours\n",
    "Morning: 8-12 hours\n",
    "Early afternoon: 12-16 hours\n",
    "Late afternoon: 16-20 hours\n",
    "Evening: 20-24 hours -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"base_features.csv\")\n",
    "print(df[\"publishedAtDate\"][977])\n",
    "\n",
    "df[\"publishedAtDate\"] = pd.to_datetime(\n",
    "    df[\"publishedAtDate\"], format=\"%Y-%m-%dT%H:%M:%S\"\n",
    ")\n",
    "\n",
    "df[\"year\"] = df[\"publishedAtDate\"].dt.year\n",
    "df[\"month\"] = df[\"publishedAtDate\"].dt.month\n",
    "df[\"dayofweek\"] = df[\"publishedAtDate\"].dt.dayofweek\n",
    "df[\"elapsed_days\"] = (datetime.today() - df[\"publishedAtDate\"]).dt.days\n",
    "df[\"when_on_day_4hbin\"] = pd.cut(\n",
    "    df[\"publishedAtDate\"].dt.hour,\n",
    "    bins=[-1, 4, 8, 12, 16, 20, 24],\n",
    "    labels=[0, 1, 2, 3, 4, 5],\n",
    ")\n",
    "\n",
    "df[\"when_on_day_hour\"] = df[\"publishedAtDate\"].dt.hour\n",
    "\n",
    "print(df[\"when_on_day_4hbin\"].isna().sum())\n",
    "print(df.loc[df[\"when_on_day_4hbin\"].isna(), \"publishedAtDate\"])\n",
    "\n",
    "print(\n",
    "    df[\n",
    "        [\n",
    "            \"publishedAtDate\",\n",
    "            \"year\",\n",
    "            \"month\",\n",
    "            \"dayofweek\",\n",
    "            \"elapsed_days\",\n",
    "            \"when_on_day_4hbin\",\n",
    "            \"when_on_day_hour\",\n",
    "        ]\n",
    "    ].head(10)\n",
    ")\n",
    "\n",
    "df.to_csv(\"feature_enriched_tab.csv\", index=False)\n",
    "df.to_excel(\"feature_enriched_tab.xlsx\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nur für mich ein Test, wie ich ein Basic Decsion Tree anwende und für grobes Gefühl, wie aussagekräftig das alles ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"feature_enriched_tab.csv\")\n",
    "\n",
    "df = df[\n",
    "    [\n",
    "        \"stars\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"likesCount\",\n",
    "        \"reviewerNumberOfReviews\",\n",
    "        \"isLocalGuide\",\n",
    "        \"dayofweek\",\n",
    "        \"elapsed_days\",\n",
    "        \"when_on_day_4hbin\",\n",
    "        \"label\",\n",
    "    ]\n",
    "]\n",
    "df[\"label\"] = (df[\"label\"] == \"real\").astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(\"label\", axis=1), df[\"label\"], test_size=0.2, random_state=11\n",
    ")\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"Decision tree accuracy: {score:.2f}\")\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "\n",
    "plt.ylabel(\"Relative Importance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bild: Feature Generierung\n",
    "\n",
    "### Feature Extrahieren über Pretrained ResNet-18 Architektur und in Dataframe abspeichern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"feature_enriched_tab.csv\")\n",
    "image_urls = df[\"reviewImageUrls/0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained ResNet-18 model\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "# Remove the last fully connected layer\n",
    "modules = list(resnet.children())[:-1]\n",
    "resnet = torch.nn.Sequential(*modules)\n",
    "# Set the model to evaluation mode\n",
    "resnet.eval()\n",
    "\n",
    "# Define a function to extract features for a single image\n",
    "def extract_image_features(image_url):\n",
    "    # Load image and preprocess\n",
    "    img = Image.open(requests.get(image_url, stream=True).raw)\n",
    "    img = transforms.ToTensor()(img)\n",
    "    img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    # Extract features\n",
    "    with torch.no_grad():\n",
    "        features = resnet(img)\n",
    "        features = features.squeeze().numpy()\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "counter = 0\n",
    "feature_vectors = []\n",
    "for image_url in image_urls:\n",
    "    try:\n",
    "        counter += 1\n",
    "        print(f'{counter}:\\tExtracting features from {image_url}')\n",
    "        features = extract_image_features(image_url)\n",
    "    except:\n",
    "        print(f'Error extracting features from {image_url}. Replaces with NaN.')\n",
    "        features = np.full((512,), np.nan)\n",
    "    feature_vectors.append(features)\n",
    "\n",
    "feature_df = pd.DataFrame(feature_vectors, columns=[f'feature_{i}' for i in range(512)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([df, feature_df], axis=1)\n",
    "print(\"added features to the original dataset.\")\n",
    "\n",
    "print(new_df.iloc[0])\n",
    "# new_df.to_csv('feature_enriched_tab_img.csv', index=False)\n",
    "# new_df.to_excel('feature_enriched_tab_img.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize as PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Load your dataframe\n",
    "df = pd.read_csv('feature_enriched_tab_img.csv')\n",
    "\n",
    "# drop row with index 764\n",
    "df = df.drop(764)\n",
    "\n",
    "# Select feature columns and label\n",
    "# can you drop all \n",
    "features = df.iloc[:, 0:1].join(df.iloc[:, 24:])\n",
    "\n",
    "\n",
    "# drop all rows with NaN values in feature columns\n",
    "features = features.dropna(subset=features.columns[1:], how='all')\n",
    "\n",
    "# Define color map\n",
    "color_map = {'fake': 'red', 'real': 'green'}\n",
    "\n",
    "# Map labels to colors\n",
    "colors = features['label'].apply(lambda x: color_map[x])\n",
    "\n",
    "# Apply t-SNE to reduce dimensionality\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200)\n",
    "tsne_features = tsne.fit_transform(features.iloc[:, 1:])\n",
    "\n",
    "# Visualize the reduced features, colored by label\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=colors, alpha=0.5)\n",
    "plt.title('t-SNE visualization of features')\n",
    "plt.xlabel('t-SNE feature 1')\n",
    "plt.ylabel('t-SNE feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataframe\n",
    "df = pd.read_csv('feature_enriched_tab_img.csv')\n",
    "\n",
    "# drop row with index 764\n",
    "df = df.drop(764)\n",
    "\n",
    "# Select feature columns and label\n",
    "features = df.iloc[:, 0:1].join(df.iloc[:, 24:])\n",
    "\n",
    "# drop all rows with NaN values in feature columns\n",
    "features = features.dropna(subset=features.columns[1:], how='all')\n",
    "\n",
    "# Define color map\n",
    "color_map = {'fake': 'red', 'real': 'green'}\n",
    "\n",
    "# Map labels to colors\n",
    "colors = features['label'].apply(lambda x: color_map[x])\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=2)\n",
    "pca_features = pca.fit_transform(features.iloc[:, 1:])\n",
    "\n",
    "# Visualize the reduced features, colored by label\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_features[:, 0], pca_features[:, 1], c=colors, alpha=0.5, s=50)\n",
    "plt.xlabel('PCA Komponente 1', fontsize=14)\n",
    "plt.ylabel('PCA Komponente 2', fontsize=14)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=10)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend(handles=[plt.scatter([], [], c='red', label='Fake Bild', alpha=0.5, s=50),\n",
    "                     plt.scatter([], [], c='green', label='Echtes Bild', alpha=0.5, s=50)],\n",
    "           loc='upper right', fontsize=12)\n",
    "plt.savefig('feature_extraction.svg', format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der Features bzw. der Feature Map \n",
    "Visualierung der Durch das CNN gejagten Bilder. Am Ende kommen die Features raus..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_layer_features(model, layer_num, input_img):\n",
    "    # Get the layer to visualize\n",
    "    layer_num_map = {0: (0, 0), 1: (0, 1), 2: (1, 0), 3: (1, 1),\n",
    "                     4: (2, 0), 5: (2, 1), 6: (3, 0), 7: (3, 1)}\n",
    "    print(f\"Layer_num{layer_num_map[layer_num]}\")\n",
    "    stage_num, block_num = layer_num_map[layer_num]\n",
    "    layer = getattr(model, f'layer{stage_num+1}')[block_num]\n",
    "\n",
    "    # Create a forward hook to get the layer's output\n",
    "    outputs = []\n",
    "    def hook(module, input, output):\n",
    "        outputs.append(output)\n",
    "    layer.register_forward_hook(hook)\n",
    "\n",
    "    # Forward pass the input image through the model\n",
    "    _ = model(input_img)\n",
    "\n",
    "    # Get the output tensor and convert to numpy array\n",
    "    feature_maps = outputs[0].detach().numpy()\n",
    "\n",
    "    # Plot the feature maps as a grid\n",
    "    fig, axs = plt.subplots(nrows=8, ncols=8, figsize=(24, 24))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(2):\n",
    "        axs[i].imshow(feature_maps[0, i, :, :], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    fig.savefig(f\"layer{layer_num}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "for i in range(7):\n",
    "    visualize_layer_features(resnet, i, input_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to visualize the feature maps of a layer\n",
    "def visualize_layer_features(model, layer_num, input_img):\n",
    "    # Get the layer to visualize\n",
    "    layer = model.layer1[layer_num] if layer_num < 4 else model.layer2[layer_num - 4] \\\n",
    "            if layer_num < 8 else model.layer3[layer_num - 8] \\\n",
    "            if layer_num < 12 else model.layer4[layer_num - 12]\n",
    "\n",
    "    # Create a forward hook to get the layer's output\n",
    "    outputs = []\n",
    "    def hook(module, input, output):\n",
    "        outputs.append(output)\n",
    "    layer.register_forward_hook(hook)\n",
    "\n",
    "    # Forward pass the input image through the model\n",
    "    _ = model(input_img)\n",
    "\n",
    "    # Get the output tensor and convert to numpy array\n",
    "    feature_maps = outputs[0].detach().numpy()\n",
    "\n",
    "    # Plot the feature maps as a grid\n",
    "    fig, axs = plt.subplots(nrows=8, ncols=8, figsize=(12, 12))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(64):\n",
    "        axs[i].imshow(feature_maps[0, i, :, :], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    fig.savefig(f\"layer{layer_num}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Load an example image\n",
    "img_path = '02_Images/fake_image_url_2/43_ChZDSUhNMG9nS0VJQ0FnSURRdTh6UEJnEAEF_fake_reviewImageUrls_2.png'\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_img = transform(img)\n",
    "input_img = input_img.unsqueeze(0)\n",
    "\n",
    "# Create a directory to save the feature maps\n",
    "if not os.path.exists('feature_maps'):\n",
    "    os.makedirs('feature_maps')\n",
    "\n",
    "# Load the pre-trained ResNet-18 model\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "# Visualize the feature maps for each layer\n",
    "for i in range(2):\n",
    "    visualize_layer_features(resnet, i, input_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the pre-trained ResNet-18 model\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "# Define a function to visualize the feature maps of a layer\n",
    "def visualize_layer_features(layer_num, input_img):\n",
    "    # Get the layer to visualize\n",
    "    layer = resnet.layer1[layer_num]\n",
    "\n",
    "    # Create a forward hook to get the layer's output\n",
    "    outputs = []\n",
    "    def hook(module, input, output):\n",
    "        outputs.append(output)\n",
    "    layer.register_forward_hook(hook)\n",
    "\n",
    "    # Forward pass the input image through the model\n",
    "    _ = resnet(input_img)\n",
    "\n",
    "    # Get the output tensor and convert to numpy array\n",
    "    feature_maps = outputs[0].detach().numpy()\n",
    "\n",
    "    # Plot the feature maps as a grid\n",
    "    fig, axs = plt.subplots(nrows=8, ncols=8, figsize=(12, 12))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(64):\n",
    "        axs[i].imshow(feature_maps[0, i, :, :], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    fig.savefig(f\"layerWW{layer_num}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Load an example image\n",
    "img_path = '02_Images/fake_image_url_2/43_ChZDSUhNMG9nS0VJQ0FnSURRdTh6UEJnEAEF_fake_reviewImageUrls_2.png'\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_img = transform(img)\n",
    "input_img = input_img.unsqueeze(0)\n",
    "\n",
    "# Create a directory to save the feature maps\n",
    "if not os.path.exists('feature_maps'):\n",
    "    os.makedirs('feature_maps')\n",
    "\n",
    "# Visualize the feature maps for each layer\n",
    "for i in range(4):\n",
    "    visualize_layer_features(i, input_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a function to perform activation maximization on a given feature and save the result to disk\n",
    "def visualize_and_save_feature(model, feature_index, save_dir, num_iterations=500):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define a random input image\n",
    "    input_image = torch.randn(1, 3, 224, 224, requires_grad=True)\n",
    "\n",
    "    # Define a transformation to preprocess the input image\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Define an optimizer to update the input image\n",
    "    optimizer = torch.optim.Adam([input_image], lr=0.1)\n",
    "\n",
    "    # Perform activation maximization for a certain number of iterations\n",
    "    for i in range(num_iterations):\n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        output = model(input_image)\n",
    "\n",
    "        # Compute the mean activation of the specified feature\n",
    "        feature_activation = output[0, feature_index].mean()\n",
    "\n",
    "        # Compute the gradient of the feature activation with respect to the input image\n",
    "        feature_activation.backward()\n",
    "\n",
    "        # Update the input image\n",
    "        optimizer.step()\n",
    "\n",
    "    # Convert the input image to a numpy array and unnormalize it\n",
    "    input_image = input_image.detach().numpy()[0]\n",
    "    input_image = (input_image * np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))) + np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "    input_image = np.clip(input_image, 0, 1)\n",
    "\n",
    "    # Save the input image to disk\n",
    "    filename = f'feature_{feature_index}.png'\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    plt.imsave(save_path, np.transpose(input_image, (1, 2, 0)))\n",
    "\n",
    "# Visualize and save the first 3 features\n",
    "save_dir = 'feature_visualizations'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for i in range(511, 512):\n",
    "    visualize_and_save_feature(model, i+1, save_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained ResNet-18 model\n",
    "resnet = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "\n",
    "# Get the first convolutional layer\n",
    "conv1 = resnet.conv1\n",
    "\n",
    "# Generate feature visualizations\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        filter_idx = i * 8 + j\n",
    "        filter_img = conv1.weight.data[filter_idx].cpu().numpy().transpose(1, 2, 0)\n",
    "        axs[i, j].imshow(filter_img)\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text: Feature Generierung\n",
    "\n",
    "1. Feature extrahieren über PNLP Paket, wie z.B: lenth, adverb, Großklein, Rechtschriebung, Smiley-Nutzung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError bei Text:    We are here last night, December 17th 2021, for my my husband's 28th birthday.\n",
      "\n",
      "We have lived in Baldwin for 2 years and those years have been pretty rough, we were so lucky to find an apartment in sweet and quiet Baldwin City. We love it here and plan on buying a home. We've experienced quite a few events here but this was our first local restaurant. We were finally able to come to The Wooden Spoke after hearing so much about it and we brought friends from out of town.\n",
      "\n",
      "What a charming, down-home, relaxed place. The parking lot felt like you were pulling into a old-time drive in, but you get out of your car and reach the door and it feels like you are standing outside of someone's well-loved home. The tables reminded me of my own kitchen tables in my childhood home. I felt comfortable as soon as I sat down. The waitress was extremely attentive, her energy was calm and sincere. Our drink orders were taken immediately, our appetizers came out quickly and the entrees were the best home cooking we all have had in many years.\n",
      "\n",
      "We ordered the KC strip, the ribeye, the bourban steak and the spoke burger, spoke fries, mash potatoes, the chilli, mozzarella sticks, potato skins, and the wings in this beautiful honey brown sauce that was sweet, spicy, smoky and honestly it was incredible. I love WINGS and these took the trophy from me and my friends!\n",
      "\n",
      "Our food and plates were hot, the food was fast. All the steaks were cooked as asked, all steaks were medium rare, juicy, delicious and quite big. Burger was done just well and had a classic burger taste.\n",
      "\n",
      "The alcoholic beverages were delicious and made strong.\n",
      "\n",
      "My daughter ordered the kids chicken strips and she said they were very good, we loved the fries. The spoke burger was amazing and the mustard tasted homemade. My husband especially loved the chilli. Overall, the food was spectacular. The service was fast and friendly, the environment was clean and comfy. We will definitely be back.\n",
      "\n",
      "Thank you wooden spoke staff and mad respect and kudos to the Chef who made an unforgettable night full of nostalgic decor, warm and friendly interaction and phenomenal home-cooking! See you again soon!!\n",
      "\n",
      "I wish I could add more photos but it was such a good time, I didn't think about taking a bunch, I just soaked in the night! ⚪️\n",
      "RuntimeError bei Text:    I am disgusted. As I just sit in this bed because I don’t want me feet all over who knows how many guests before me. We stopped here so we didn’t have to continue to drive on our long trip. All we wanted was a clean hotel where we could sleep and shower with our two children! The shower even has black hairs! Black hairs were all over the first room and we asked to switch to find the same thing. The floors are not vacuumed at all. It’s unreal. I have never stayed at a Wyndham hotel but it looked VERY nice in the photos and I never imagined it would be this dirty. The cleaning in this hotel... well there obviously wasn’t any real cleaning done. There should never be leftovers from other strangers in a hotel I paid for. I would have rather drove three more hours then not have a nice place to sleep and shower at. I am very upset and I have NEVER in my life wrote a review. I am not hard to please! The Wi-Fi code does not work. The phone does not work. The phone plug keeps falling out every time I pick up the phone. The top layer of the sheet had dirt on it or food. Looks like cake. I stay at many hotel. This is unacceptable. Also On top of this. I was told you guys price match. There was a deal online that was $20 cheaper than the right here and they said they could not do it. So even more annoyed right now that I came here because I thought I was getting a deal. After having heart issues with my bank it took a little longer than necessary which is totally my fault. My car got blocked because were out of town. I would have paid the extra money to stay in a clean hotel but after carrying all of her bags and everything up for four people, me and my husband have to work tomorrow. And both of our kids are ready for bed. None of us will be showering in the bathroom and we are all disgusted to the point we don’t want to get off our beds u less we have our shoes on.\n",
      "Livid to say the least. The cleaning lady left a envelope for a tip???? She has to be joking. She needs to be fired. Oh!!! and the what class that my daughter went to use had a big black hair in it. Look close at pics! Gross!!!!\n",
      "\n",
      "Staff is very friendly. I will say. They were nice. Although a guy followed us up to make sure the second room was clean. It wasn’t.. and he walked away and did nothing. I am convinced all rooms are this dirty or I would ask for another!\n",
      "RuntimeError bei Text:    This post should have been made in March 2021 but the trauma of the night is still a struggle for me.\n",
      "\n",
      "I had been here once before and had a decent time. We paid extra for VIP and side lot parking. This night that lot was full and we parked on a side lot that was “monitored / guarded.” We got there and did not do a VIP experience as we had time to kill. It felt like the line did not move and easily an hour after standing in line we made it to the front of the building. We were 4 or 5 groups back and the line completely stopped. Across from us was the VIP line for the front door and they were not permitted to enter either. Several people from both lines would knock and ask questions but were disrespected.\n",
      "\n",
      "Visitors had purchased tickets online and did not wish to continue to wait. They knocked to see if they could get a date adjustment and still the doors would be slammed in their face. There wasn’t a special uniform for the workers so when people knocked some would be allowed entry but no one updated the crowd outside. Eventually after a 2 hour wait (from arrival) the security guard shared they were short staffed and had to allow some people to clear out. There was no apology or anything just blatant disrespect to paying customers.\n",
      "\n",
      "When we arrived and paid to park in the trap museum lot it was early evening and the lot was lit up by sunlight. By the time we finished the museum we came out to night time. The lot we paid to park in was not well lit when we returned to my vehicle. I found my vehicle damaged, articles stolen and when I asked the attendant he radioed a manager as he was too busy and didn’t know anything happened.\n",
      "\n",
      "We spoke with the representative or manager who went by the name A1. He did not provide his full name but assured us they would fix my window. This time of evening we could not get anyone out and due to Covid mobile window repairs were limited. Still A1 shared the museum would cover the costs. The police came and took a report along with dusting for fingerprints. The thieves not only broke my window they damaged my glove compartment that had my Glock locked inside of it. They stole work items to include files, electronics and my work laptop. The serial numbers of all of my items were added to the police report.\n",
      "\n",
      "I am a business owner and could not work for a month as I had to work to replace the electronics, files and missed opportunities to make money as I did not have the tools. I shared this with A1 and a lady named Adlia along with sharing the price point for replacing my window. I submitted all of my receipts for my window, loss work and equipment in hopes they would replace my work electronics as a thank you to a military veteran. It was wishful thinking but they mentioned they were short staffed, they pretended to understand how this interrupted my night and work as well.\n",
      "\n",
      "They offered to cashapp me $300 for my window and a we are sorry that happened. Window itself was $300 and that did not include emergency installation. This place gave me a real life experience of what it means to support the trap.\n",
      "\n",
      "I have pictures of my vehicle along with text conversations below.\n",
      "RuntimeError bei Text:    1 star for a subpar/gross experience at Chicago Getaway Hostel. I rented a private room for 3 nights looking for a clean/decent place to sleep and shower while I was in the city for a work project. Chicago Getaway Hostel did not fit the bill.\n",
      "\n",
      "The Hostel is in a beautiful Lincoln Park neighborhood with tons of giant trees and you really can't find a better location to get the LP vibe but then walk a block to hop on trains/buses. The cost for a private room is comparable to a hotel room, but I chose this place because it's location was within walking distance to where I was going to be working. After looking at reviews and photos of the hostel, it seemed like a very modern and clean place that I would be comfortable staying at... unfortunately the photos were deceiving and the reviews did not represent my experience.\n",
      "\n",
      "When I walked up to the building, I had to walk through a crowd of people gathering on the sidewalk outside the hostel smoking (great for my asthma) to enter the building. This happened every time I entered/exited the building over the next few days, which was a real turn off to me. The check in process was quick - the person checking me in rushed through all of the instructions and gave me no written document that verified what he went over, so that was fun.\n",
      "\n",
      "My room looked nice at first glance - 2 bunk beds, a desk, shower/toilet/sink. All the essentials. Upon further investigation here's what I found (some photos attached)... the bathroom was absolutely disgusting. I don't know when it was last cleaned, but it had to have been a long time. The amount of dirt/grime built up in that shower made me feel dirtier than I was when I walked in. One shouldn't have to buy flip flops to shower in a private room bathroom they rented. There was buildup ON THE SHOWER HEAD where the clean water is supposed to come out of but there was nastiness caked on so it passed through that first.\n",
      "\n",
      "The beds were pretty uncomfortable. The mattress was very thin and I could feel the bars through it, so it was rough sleeping. A majority of the linens had a ton of stains/loose hairs on them (especially the pillows) and they were very rough in texture. All of this combined made me feel very gross and like the room hadn't been cleaned at all. For the price of a hotel room I'd expect a much higher level of cleanliness from this place.\n",
      "\n",
      "Needless to say, I will not be back.\n",
      "Fertig mit 1. Block.\n",
      "Fertig mit 2. Block.\n",
      "Fertig mit 3. Block.\n",
      "Fertig mit 4. Block.\n",
      "Fertig mit 5. Block.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"feature_enriched_tab_img.csv\")\n",
    "\n",
    "def entire_capitalized_percentage(text):\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    words = [word for word in words if word.lower() != \"i\"]\n",
    "    num_capitalized = sum([1 for word in words if word.isupper()])\n",
    "    return num_capitalized / num_words\n",
    "\n",
    "def count_emojis(text):\n",
    "    emoji_count =  0\n",
    "    for character in text:\n",
    "        if character in emoji.EMOJI_DATA:\n",
    "            emoji_count += 1\n",
    "    return emoji_count\n",
    "\n",
    "def emojji_per_word_ratio(text):\n",
    "    emoji_count =  0\n",
    "    for character in text:\n",
    "        if character in emoji.EMOJI_DATA:\n",
    "            emoji_count += 1\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return emoji_count / num_words\n",
    "    \n",
    "def avg_word_length(text):\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        total_length = sum([len(word) for word in words])\n",
    "        return total_length / num_words\n",
    "\n",
    "def avg_sentence_length(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        total_length = sum([len(sentence.split()) for sentence in sentences])\n",
    "        return total_length / num_sentences\n",
    "\n",
    "def extract_pos_tags(text):\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    return pos_tags\n",
    "\n",
    "def perform_sentiment_analysis(text):\n",
    "    try:\n",
    "        sentiment = sentiment_task(text)\n",
    "        sentiment_label = sentiment[0]['label']\n",
    "        #print(sentiment_label)\n",
    "        return sentiment_label\n",
    "    except RuntimeError:\n",
    "        print(f\"RuntimeError bei Text:    {text}\")\n",
    "        return \"check_manually\"\n",
    "   \n",
    "def text_spelling_error_quota(text):\n",
    "    blob = TextBlob(text)\n",
    "    words = blob.words\n",
    "    num_words = len(words)\n",
    "    num_errors = sum([not w.spellcheck()[0][1] for w in blob.words])\n",
    "    return num_errors / num_words\n",
    "\n",
    "def calculate_punctuation_ratio(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    ratio_list = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        num_punctuations = sum([1 for word in words if word in string.punctuation])\n",
    "        num_words = len(words)\n",
    "        if num_words > 0:\n",
    "            punctuation_ratio = num_punctuations / num_words\n",
    "            ratio_list.append(punctuation_ratio)    \n",
    "    if len(ratio_list) > 0:\n",
    "        avg_punctuation_ratio = sum(ratio_list) / len(ratio_list)\n",
    "    else:\n",
    "        avg_punctuation_ratio = 0\n",
    "    return avg_punctuation_ratio\n",
    "\n",
    "def count_nouns(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    noun_count = len([word for word, tag in tagged_tokens if tag.startswith('N')])\n",
    "    return noun_count\n",
    "\n",
    "def count_adjectives(text):\n",
    "    adj_tags = ['JJ', 'JJR', 'JJS']\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    adj_count = len([word for word, tag in nltk.pos_tag(tokens) if tag in adj_tags])\n",
    "    return adj_count\n",
    "\n",
    "def count_verbs(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    verb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "    tokens = word_tokenize(text)\n",
    "    verb_count = len([word for word, tag in pos_tag(tokens) if tag in verb_tags and word.lower() not in stop_words])\n",
    "    return verb_count\n",
    "\n",
    "def count_adverbs(text): \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    adv_tags = ['RB', 'RBR', 'RBS']\n",
    "    tokens = word_tokenize(text)\n",
    "    adv_count = len([word for word, tag in pos_tag(tokens) if tag in adv_tags and word.lower() not in stop_words])\n",
    "    return adv_count\n",
    "\n",
    "def count_pronouns(text):\n",
    "    pronoun_tags = ['PRP', 'PRP$', 'WP', 'WP$']\n",
    "    tokens = word_tokenize(text)\n",
    "    pronoun_count = len([word for word, tag in pos_tag(tokens) if tag in pronoun_tags])\n",
    "    return pronoun_count\n",
    "\n",
    "def calculate_not_stopword_ratio(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    num_words = len(words)\n",
    "    not_stopword_count = len([word for word in words if word.lower() not in stop_words])\n",
    "    return not_stopword_count / num_words\n",
    "\n",
    "def calculate_stopword_ratio(text):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    num_words = len(words)\n",
    "    num_stopwords = len([word for word in words if word in stop_words])\n",
    "    return num_stopwords / num_words\n",
    "\n",
    "def calulate_stopword_to_nostopword_ratio(text): \n",
    "    return calculate_stopword_ratio(text) / calculate_not_stopword_ratio(text)\n",
    "\n",
    "def compute_modal_verb_ratio(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    modal_verbs = ['can', 'could', 'may', 'might', 'shall', 'should', 'will', 'would', 'must']\n",
    "    modal_verb_count = len([word for word in tokens if word in modal_verbs and word not in stop_words])\n",
    "    word_count = len([word for word in tokens if word not in stop_words])\n",
    "    return modal_verb_count / word_count\n",
    "\n",
    "def compute_uncertain_ratio(text):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    uncertain_words = ['yet', 'careful', 'hesitant', 'tendency', 'hit', 'undefined', 'ambivalent', 'confused', 'equivocal', 'fuzzy', 'inconclusive', 'indeterminate', 'unclear', 'uncertain', 'unsettled', 'vague']\n",
    "    uncertain_count = len([word for word in words if word in uncertain_words and word not in stop_words])\n",
    "    total_count = len(words)\n",
    "    uncertain_ratio = uncertain_count / total_count if total_count > 0 else 0.0\n",
    "    return uncertain_ratio\n",
    "\n",
    "def count_individual_words(text):\n",
    "    individual_words = ['I', 'me', 'my', 'mine', 'myself']\n",
    "    tokens = word_tokenize(text)\n",
    "    individual_count = len([word for word in tokens if word.lower() in individual_words])\n",
    "    return individual_count\n",
    "\n",
    "def count_group_words(text):\n",
    "    group_words = ['we', 'us', 'our', 'ours', 'ourselves']\n",
    "    tokens = word_tokenize(text)\n",
    "    group_count = len([word for word in tokens if word.lower() in group_words])\n",
    "    return group_count\n",
    "\n",
    "def count_self_words(text):\n",
    "    self_words = ['self', 'myself', 'ourselves']\n",
    "    tokens = word_tokenize(text)\n",
    "    self_count = len([word for word in tokens if word.lower() in self_words])\n",
    "    return self_count\n",
    "\n",
    "def individual_ratio(text):\n",
    "    total_words = len(word_tokenize(text))\n",
    "    individual_count = count_individual_words(text)\n",
    "    return individual_count / total_words\n",
    "\n",
    "def group_ratio(text):\n",
    "    total_words = len(word_tokenize(text))\n",
    "    group_count = count_group_words(text)\n",
    "    return group_count / total_words\n",
    "\n",
    "def self_ratio(text):\n",
    "    total_words = len(word_tokenize(text))\n",
    "    self_count = count_self_words(text)\n",
    "    return self_count / total_words\n",
    "\n",
    "df['text_length'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "df['text_length_char'] = df['text'].apply(len)\n",
    "df['text_punctuation'] = df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "df['text_avg_word_length'] = df['text'].apply(avg_word_length)\n",
    "df['text_avg_sentence_length'] = df['text'].apply(avg_sentence_length)\n",
    "df['text_sentiment'] = df['text'].apply(perform_sentiment_analysis)\n",
    "print('Fertig mit 1. Block.')\n",
    "\n",
    "df['text_emoji_count'] = df['text'].apply(count_emojis)\n",
    "df['text_count_verbs'] = df['text'].apply(count_verbs)\n",
    "df['text_count_adjectives'] = df['text'].apply(count_adjectives)\n",
    "df['text_count_adverbs'] = df['text'].apply(count_adverbs)\n",
    "df['text_count_pronouns'] = df['text'].apply(count_pronouns)\n",
    "df['text_count_nouns'] = df['text'].apply(count_nouns)\n",
    "df.to_csv('features_enriched_tab_img_text.csv', index=False)\n",
    "print('Fertig mit 2. Block.')\n",
    "\n",
    "df['text_no_stopword_Ratio'] = df['text'].apply(calculate_not_stopword_ratio)\n",
    "df['text_stopword_ratio'] = df['text'].apply(calculate_stopword_ratio)\n",
    "df['text_stopword_to_nostopword_ratio'] = df['text'].apply(calulate_stopword_to_nostopword_ratio)\n",
    "df['text_entired_capitalized_ratio'] = df['text'].apply(entire_capitalized_percentage)\n",
    "df['text_punctuation_ratio'] = df['text'].apply(calculate_punctuation_ratio)\n",
    "df.to_csv('features_enriched_tab_img_text.csv', index=False)\n",
    "print('Fertig mit 3. Block.')\n",
    "\n",
    "df['text_spelling_error_quota'] = df['text'].apply(text_spelling_error_quota)\n",
    "df['text_modal_verb_ratio'] = df['text'].apply(compute_modal_verb_ratio)\n",
    "df['text_uncertain_ratio'] = df['text'].apply(compute_uncertain_ratio)\n",
    "df['text_individual_count'] = df['text'].apply(count_individual_words)\n",
    "print('Fertig mit 4. Block.')\n",
    "\n",
    "df['text_group_count'] = df['text'].apply(count_group_words)\n",
    "df['text_self_count'] = df['text'].apply(count_self_words)\n",
    "df['text_individual_ratio'] = df['text'].apply(individual_ratio)\n",
    "df['text_group_ratio'] = df['text'].apply(group_ratio)\n",
    "df['text_self_ratio'] = df['text'].apply(self_ratio)\n",
    "print('Fertig mit 5. Block.')\n",
    "\n",
    "df.to_csv('features_enriched_tab_img_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    1085\n",
      "negative     260\n",
      "neutral       65\n",
      "Name: text_sentiment, dtype: int64\n",
      "We are here last night, December 17th 2021, for my my husband's 28th birthday.\n",
      "\n",
      "We have lived in Baldwin for 2 years and those years have been pretty rough, we were so lucky to find an apartment in sweet and quiet Baldwin City. We love it here and plan on buying a home. We've experienced quite a few events here but this was our first local restaurant. We were finally able to come to The Wooden Spoke after hearing so much about it and we brought friends from out of town.\n",
      "\n",
      "What a charming, down-home, relaxed place. The parking lot felt like you were pulling into a old-time drive in, but you get out of your car and reach the door and it feels like you are standing outside of someone's well-loved home. The tables reminded me of my own kitchen tables in my childhood home. I felt comfortable as soon as I sat down. The waitress was extremely attentive, her energy was calm and sincere. Our drink orders were taken immediately, our appetizers came out quickly and the entrees were the best home cooking we all have had in many years.\n",
      "\n",
      "We ordered the KC strip, the ribeye, the bourban steak and the spoke burger, spoke fries, mash potatoes, the chilli, mozzarella sticks, potato skins, and the wings in this beautiful honey brown sauce that was sweet, spicy, smoky and honestly it was incredible. I love WINGS and these took the trophy from me and my friends!\n",
      "\n",
      "Our food and plates were hot, the food was fast. All the steaks were cooked as asked, all steaks were medium rare, juicy, delicious and quite big. Burger was done just well and had a classic burger taste.\n",
      "\n",
      "The alcoholic beverages were delicious and made strong.\n",
      "\n",
      "My daughter ordered the kids chicken strips and she said they were very good, we loved the fries. The spoke burger was amazing and the mustard tasted homemade. My husband especially loved the chilli. Overall, the food was spectacular. The service was fast and friendly, the environment was clean and comfy. We will definitely be back.\n",
      "\n",
      "Thank you wooden spoke staff and mad respect and kudos to the Chef who made an unforgettable night full of nostalgic decor, warm and friendly interaction and phenomenal home-cooking! See you again soon!!\n",
      "\n",
      "I wish I could add more photos but it was such a good time, I didn't think about taking a bunch, I just soaked in the night! ⚪️\n",
      "__________________________________________________________________________________________________________\n",
      "I am disgusted. As I just sit in this bed because I don’t want me feet all over who knows how many guests before me. We stopped here so we didn’t have to continue to drive on our long trip. All we wanted was a clean hotel where we could sleep and shower with our two children! The shower even has black hairs! Black hairs were all over the first room and we asked to switch to find the same thing. The floors are not vacuumed at all. It’s unreal. I have never stayed at a Wyndham hotel but it looked VERY nice in the photos and I never imagined it would be this dirty. The cleaning in this hotel... well there obviously wasn’t any real cleaning done. There should never be leftovers from other strangers in a hotel I paid for. I would have rather drove three more hours then not have a nice place to sleep and shower at. I am very upset and I have NEVER in my life wrote a review. I am not hard to please! The Wi-Fi code does not work. The phone does not work. The phone plug keeps falling out every time I pick up the phone. The top layer of the sheet had dirt on it or food. Looks like cake. I stay at many hotel. This is unacceptable. Also On top of this. I was told you guys price match. There was a deal online that was $20 cheaper than the right here and they said they could not do it. So even more annoyed right now that I came here because I thought I was getting a deal. After having heart issues with my bank it took a little longer than necessary which is totally my fault. My car got blocked because were out of town. I would have paid the extra money to stay in a clean hotel but after carrying all of her bags and everything up for four people, me and my husband have to work tomorrow. And both of our kids are ready for bed. None of us will be showering in the bathroom and we are all disgusted to the point we don’t want to get off our beds u less we have our shoes on.\n",
      "Livid to say the least. The cleaning lady left a envelope for a tip???? She has to be joking. She needs to be fired. Oh!!! and the what class that my daughter went to use had a big black hair in it. Look close at pics! Gross!!!!\n",
      "\n",
      "Staff is very friendly. I will say. They were nice. Although a guy followed us up to make sure the second room was clean. It wasn’t.. and he walked away and did nothing. I am convinced all rooms are this dirty or I would ask for another!\n",
      "__________________________________________________________________________________________________________\n",
      "This post should have been made in March 2021 but the trauma of the night is still a struggle for me.\n",
      "\n",
      "I had been here once before and had a decent time. We paid extra for VIP and side lot parking. This night that lot was full and we parked on a side lot that was “monitored / guarded.” We got there and did not do a VIP experience as we had time to kill. It felt like the line did not move and easily an hour after standing in line we made it to the front of the building. We were 4 or 5 groups back and the line completely stopped. Across from us was the VIP line for the front door and they were not permitted to enter either. Several people from both lines would knock and ask questions but were disrespected.\n",
      "\n",
      "Visitors had purchased tickets online and did not wish to continue to wait. They knocked to see if they could get a date adjustment and still the doors would be slammed in their face. There wasn’t a special uniform for the workers so when people knocked some would be allowed entry but no one updated the crowd outside. Eventually after a 2 hour wait (from arrival) the security guard shared they were short staffed and had to allow some people to clear out. There was no apology or anything just blatant disrespect to paying customers.\n",
      "\n",
      "When we arrived and paid to park in the trap museum lot it was early evening and the lot was lit up by sunlight. By the time we finished the museum we came out to night time. The lot we paid to park in was not well lit when we returned to my vehicle. I found my vehicle damaged, articles stolen and when I asked the attendant he radioed a manager as he was too busy and didn’t know anything happened.\n",
      "\n",
      "We spoke with the representative or manager who went by the name A1. He did not provide his full name but assured us they would fix my window. This time of evening we could not get anyone out and due to Covid mobile window repairs were limited. Still A1 shared the museum would cover the costs. The police came and took a report along with dusting for fingerprints. The thieves not only broke my window they damaged my glove compartment that had my Glock locked inside of it. They stole work items to include files, electronics and my work laptop. The serial numbers of all of my items were added to the police report.\n",
      "\n",
      "I am a business owner and could not work for a month as I had to work to replace the electronics, files and missed opportunities to make money as I did not have the tools. I shared this with A1 and a lady named Adlia along with sharing the price point for replacing my window. I submitted all of my receipts for my window, loss work and equipment in hopes they would replace my work electronics as a thank you to a military veteran. It was wishful thinking but they mentioned they were short staffed, they pretended to understand how this interrupted my night and work as well.\n",
      "\n",
      "They offered to cashapp me $300 for my window and a we are sorry that happened. Window itself was $300 and that did not include emergency installation. This place gave me a real life experience of what it means to support the trap.\n",
      "\n",
      "I have pictures of my vehicle along with text conversations below.\n",
      "__________________________________________________________________________________________________________\n",
      "1 star for a subpar/gross experience at Chicago Getaway Hostel. I rented a private room for 3 nights looking for a clean/decent place to sleep and shower while I was in the city for a work project. Chicago Getaway Hostel did not fit the bill.\n",
      "\n",
      "The Hostel is in a beautiful Lincoln Park neighborhood with tons of giant trees and you really can't find a better location to get the LP vibe but then walk a block to hop on trains/buses. The cost for a private room is comparable to a hotel room, but I chose this place because it's location was within walking distance to where I was going to be working. After looking at reviews and photos of the hostel, it seemed like a very modern and clean place that I would be comfortable staying at... unfortunately the photos were deceiving and the reviews did not represent my experience.\n",
      "\n",
      "When I walked up to the building, I had to walk through a crowd of people gathering on the sidewalk outside the hostel smoking (great for my asthma) to enter the building. This happened every time I entered/exited the building over the next few days, which was a real turn off to me. The check in process was quick - the person checking me in rushed through all of the instructions and gave me no written document that verified what he went over, so that was fun.\n",
      "\n",
      "My room looked nice at first glance - 2 bunk beds, a desk, shower/toilet/sink. All the essentials. Upon further investigation here's what I found (some photos attached)... the bathroom was absolutely disgusting. I don't know when it was last cleaned, but it had to have been a long time. The amount of dirt/grime built up in that shower made me feel dirtier than I was when I walked in. One shouldn't have to buy flip flops to shower in a private room bathroom they rented. There was buildup ON THE SHOWER HEAD where the clean water is supposed to come out of but there was nastiness caked on so it passed through that first.\n",
      "\n",
      "The beds were pretty uncomfortable. The mattress was very thin and I could feel the bars through it, so it was rough sleeping. A majority of the linens had a ton of stains/loose hairs on them (especially the pillows) and they were very rough in texture. All of this combined made me feel very gross and like the room hadn't been cleaned at all. For the price of a hotel room I'd expect a much higher level of cleanliness from this place.\n",
      "\n",
      "Needless to say, I will not be back.\n",
      "__________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('features_enriched_tab_img_text.csv')\n",
    "\n",
    "# print(df['text_sentiment'].value_counts())\n",
    "# print(df['text'][933])\n",
    "# print(\"__________________________________________________________________________________________________________\")\n",
    "# print(df['text'][938])\n",
    "# print(\"__________________________________________________________________________________________________________\")\n",
    "# print(df['text'][1101])\n",
    "# print(\"__________________________________________________________________________________________________________\")\n",
    "# print(df['text'][1273])\n",
    "# print(\"__________________________________________________________________________________________________________\")\n",
    "\n",
    "df.loc[933, \"text_sentiment\"] = \"positive\"\n",
    "df.loc[938, \"text_sentiment\"] = \"negative\"\n",
    "df.loc[1101, \"text_sentiment\"] = \"negative\"\n",
    "df.loc[1273, \"text_sentiment\"] = \"negative\"\n",
    "\n",
    "df.to_csv('features_enriched_tab_img_text.csv', index=False)\n",
    "df.to_excel('features_enriched_tab_img_text.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exkurs: Eigenen Img-Klassifikator trainiert und ausgwertet\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilder für Training vorberieten und\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_weitere_forschung_ohne_base.csv\")\n",
    "\n",
    "df = df.sample(n=500, random_state=9)\n",
    "df = df.sort_index()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index < 0:\n",
    "        print(f\"Index {index} schon heruntergeladen, skipped ..\")\n",
    "        continue\n",
    "    for i in range(2):\n",
    "        if not pd.isna(row[f\"reviewImageUrls/{i}\"]):\n",
    "            print(f\"Downloading image for {index}...\")\n",
    "            url = row[f\"reviewImageUrls/{i}\"]\n",
    "            filename = f\"{url.split('/')[-1]}.png\"\n",
    "            path = os.path.join(\"02_Images\", \"train\", \"real\", filename)\n",
    "            if not os.path.exists(path):\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(url, path)\n",
    "                except:\n",
    "                    print(f\"Error with {url}\")\n",
    "\n",
    "print(\"Done with downloading real images for training set.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Umsetzung mit FASTAI visual Learning als Classifizierung Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"base_keywords_sentiment_reduced.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "df_all = pd.read_csv(\"01_Data/raw_data/dataset_weitere_forschung.csv\")\n",
    "print(df_all.shape)\n",
    "\n",
    "df_all = df_all[\n",
    "    [\n",
    "        \"text\",\n",
    "        \"reviewId\",\n",
    "        \"url\",\n",
    "        \"placeId\",\n",
    "        \"categoryName\",\n",
    "        \"stars\",\n",
    "        \"title\",\n",
    "        \"reviewImageUrls/0\",\n",
    "        \"reviewImageUrls/1\",\n",
    "        \"reviewImageUrls/2\",\n",
    "        \"reviewImageUrls/3\",\n",
    "        \"reviewImageUrls/4\",\n",
    "        \"reviewImageUrls/5\",\n",
    "        \"genre\",\n",
    "    ]\n",
    "]\n",
    "df_all = df_all[df_all[\"reviewImageUrls/0\"].notna()]\n",
    "print(df_all.shape)\n",
    "df_all = df_all[~df_all[\"reviewId\"].isin(df[\"reviewId\"])]\n",
    "print(df_all.shape)\n",
    "print(df_all.columns)\n",
    "\n",
    "image_urls_cols = [\n",
    "    \"reviewImageUrls/0\",\n",
    "    \"reviewImageUrls/1\",\n",
    "    \"reviewImageUrls/2\",\n",
    "    \"reviewImageUrls/3\",\n",
    "    \"reviewImageUrls/4\",\n",
    "    \"reviewImageUrls/5\",\n",
    "]\n",
    "for col in image_urls_cols:\n",
    "    print(f\"Processing col {col}\")\n",
    "    df_all[col] = df_all[col].str.replace(\"=w150-h150-k-no-p\", \"=w256-h256-p-k-no\")\n",
    "\n",
    "print(df_all.shape)\n",
    "\n",
    "# df_all.to_csv('train_weitere_forschung_ohne_base.csv', index=False)\n",
    "# df_all.to_excel('train_weitere_forschung_ohne_base.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier nur die Auswertung. Training in colab.ipynb Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"font.family\"] = \"Book Antiqua\"\n",
    "\n",
    "df = pd.read_csv(\"base_fake_real_imgcls_pred.csv\")\n",
    "\n",
    "y_true = df[\"label\"]\n",
    "y_pred = df[\"prediction_0\"]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "recall = classification_report(y_true, y_pred, output_dict=True)[\"weighted avg\"][\n",
    "    \"recall\"\n",
    "]\n",
    "precision = classification_report(y_true, y_pred, output_dict=True)[\"weighted avg\"][\n",
    "    \"precision\"\n",
    "]\n",
    "f1_score = classification_report(y_true, y_pred, output_dict=True)[\"weighted avg\"][\n",
    "    \"f1-score\"\n",
    "]\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "\n",
    "cmap = colors.ListedColormap([\"#FFE5E4\", \"#D7F3D9\"])\n",
    "\n",
    "labels = y_true.unique()\n",
    "fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    fmt=\"g\",\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    cbar=False,\n",
    ")\n",
    "plt.xlabel(\"Vorhersage\")\n",
    "plt.ylabel(\"Tatsächlich\")\n",
    "\n",
    "plt.savefig(\"confusion_matrix_green_red.svg\", format=\"svg\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
